{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fiona Nicdao's Assignment 1"
      ],
      "metadata": {
        "id": "9Z7bfcTTtV8d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "Vm2lOB5Zdo3y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import  keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing the MNIST Dataset"
      ],
      "metadata": {
        "id": "PofcRAbftNVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#build the model based on the data\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Change the data to be split into 70% training set and 30% testing set\n",
        "x = np.concatenate((x_train, x_test))\n",
        "y = np.concatenate((y_train, y_test))\n",
        "train_size = 0.7\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=train_size,\n",
        "                                                    random_state=42)\n",
        "\n",
        "dev_size = 0.8 * x_train.shape[0]\n",
        "dev_size = int(dev_size)\n",
        "\n",
        "#shuffle the x_train (good practice)\n",
        "#seed for reproducibility\n",
        "indices = np.arange(x_train.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "x_train = x_train[indices]\n",
        "y_train = y_train[indices]\n",
        "\n",
        "# plot the image\n",
        "plt.imshow(x_train[0], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "#dividing the training dataset into 80/20 : training set/ validation set\n",
        "x_val = x_train[dev_size:] #validation sets\n",
        "y_val = y_train[dev_size:]\n",
        "\n",
        "x_train = x_train[:dev_size] #training sets\n",
        "y_train = y_train[:dev_size]\n",
        "\n",
        "#preparing training data\n",
        "#dividing them by max pixel value as a float to get all values btw 0 and 1\n",
        "x_train = (x_train/255.0).reshape(-1, 28*28)\n",
        "x_val = (x_val/255.0).reshape(-1, 28*28)\n",
        "x_test = (x_test/255.0).reshape(-1, 28*28)\n",
        "\n",
        "#make the classes one-hot encodings\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_val = tf.keras.utils.to_categorical(y_val)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "print(x_train.shape) #6000 training samples, image is 28x28 size\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "yEuwjCr1piTb",
        "outputId": "dea6430e-0248-483c-a936-911c021a9676"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(39200, 784)\n",
            "(39200, 10)\n",
            "(21000, 784)\n",
            "(21000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check step that the data is normalized between [1.0, 0.0]\n",
        "x_train[0].max(), x_train[0].min()\n",
        "# better to have it float values /"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AttxEG5XfaLJ",
        "outputId": "e54813da-9753-4a93-bdd4-8dae25af063b"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Model : MLP"
      ],
      "metadata": {
        "id": "wxNuwLkitDyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model\n",
        "class MLP(tf.keras.Model):\n",
        "  def __init__(self, num_classes, input_shape, n_layers, n_units, activation,\n",
        "               optim, loss, initializer,reg):\n",
        "      super(MLP, self).__init__()\n",
        "      self.num_classes = num_classes\n",
        "      self.input_shape = input_shape\n",
        "      self.n_layers = n_layers\n",
        "      self.n_units = n_units\n",
        "      self.activation = activation\n",
        "      self.optimizer = optim\n",
        "      self.loss = loss\n",
        "      self.initializer = initializer\n",
        "      self.regularizer = reg\n",
        "\n",
        "      self.model = self.create_model()\n",
        "\n",
        "  #build the structure of the model\n",
        "  def create_model(self):\n",
        "    model = tf.keras.Sequential() # Sequential model is just a placeholder\n",
        "    model.add(tf.keras.layers.Input(shape=self.input_shape))\n",
        "\n",
        "    for i in range(self.n_layers):\n",
        "      model.add(tf.keras.layers.Dense(self.n_units,\n",
        "                                      input_shape=self.input_shape,\n",
        "                                      activation=self.activation,\n",
        "                                      kernel_initializer = self.initializer,\n",
        "                                      kernel_regularizer= self.regularizer))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(self.num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "  def compile_model(self):\n",
        "    self.model.compile(optimizer=self.optimizer, loss=self.loss,\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "  def train_model(self, x_train, y_train, x_val, y_val, epochs=10,\n",
        "                  batch_size=32):\n",
        "    self.model.fit(x_train, y_train, epochs=epochs, batch_size=64,\n",
        "                   validation_data=(x_val, y_val))\n",
        "\n",
        "  def evaluate_model(self, x_test, y_test):\n",
        "    test_loss, test_acc = self.model.evaluate(x_test, y_test)\n",
        "    return test_loss, test_acc"
      ],
      "metadata": {
        "id": "94glye77k4NJ"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TASK 1"
      ],
      "metadata": {
        "id": "w9xiQNsJlt_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_task1 = MLP(num_classes=10,\n",
        "          input_shape=(28*28,),\n",
        "          n_layers=2,\n",
        "          n_units=100,\n",
        "          activation='relu',\n",
        "          optim= tf.keras.optimizers.SGD(learning_rate=0.0001),\n",
        "          loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "          initializer=tf.keras.initializers.HeNormal(),\n",
        "          reg = tf.keras.regularizers.l2(0.001))\n",
        "mlp_task1.compile_model()\n",
        "start = time.time()\n",
        "mlp_task1.train_model(x_train, y_train, x_val, y_val, epochs=50, batch_size=32)\n",
        "end = time.time()\n",
        "print(f\"Training time for MLP task 1: {end - start} seconds\")"
      ],
      "metadata": {
        "id": "tDRn2D_inklo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21a6173e-9b83-48aa-8e8b-db38dc906926",
        "collapsed": true
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.0977 - loss: 2.8152 - val_accuracy: 0.1051 - val_loss: 2.7562\n",
            "Epoch 2/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1101 - loss: 2.7328 - val_accuracy: 0.1261 - val_loss: 2.6862\n",
            "Epoch 3/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1402 - loss: 2.6672 - val_accuracy: 0.1686 - val_loss: 2.6277\n",
            "Epoch 4/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1874 - loss: 2.6093 - val_accuracy: 0.2189 - val_loss: 2.5756\n",
            "Epoch 5/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2368 - loss: 2.5580 - val_accuracy: 0.2684 - val_loss: 2.5273\n",
            "Epoch 6/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.2857 - loss: 2.5117 - val_accuracy: 0.3170 - val_loss: 2.4812\n",
            "Epoch 7/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3327 - loss: 2.4661 - val_accuracy: 0.3630 - val_loss: 2.4362\n",
            "Epoch 8/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3827 - loss: 2.4208 - val_accuracy: 0.4112 - val_loss: 2.3917\n",
            "Epoch 9/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4216 - loss: 2.3785 - val_accuracy: 0.4542 - val_loss: 2.3473\n",
            "Epoch 10/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4650 - loss: 2.3315 - val_accuracy: 0.4955 - val_loss: 2.3028\n",
            "Epoch 11/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4988 - loss: 2.2909 - val_accuracy: 0.5312 - val_loss: 2.2581\n",
            "Epoch 12/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5370 - loss: 2.2403 - val_accuracy: 0.5632 - val_loss: 2.2132\n",
            "Epoch 13/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5644 - loss: 2.1982 - val_accuracy: 0.5858 - val_loss: 2.1682\n",
            "Epoch 14/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5882 - loss: 2.1546 - val_accuracy: 0.6100 - val_loss: 2.1232\n",
            "Epoch 15/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6140 - loss: 2.1076 - val_accuracy: 0.6283 - val_loss: 2.0784\n",
            "Epoch 16/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6338 - loss: 2.0631 - val_accuracy: 0.6454 - val_loss: 2.0341\n",
            "Epoch 17/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.6486 - loss: 2.0206 - val_accuracy: 0.6584 - val_loss: 1.9903\n",
            "Epoch 18/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6610 - loss: 1.9802 - val_accuracy: 0.6718 - val_loss: 1.9474\n",
            "Epoch 19/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6741 - loss: 1.9344 - val_accuracy: 0.6826 - val_loss: 1.9054\n",
            "Epoch 20/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.6885 - loss: 1.8914 - val_accuracy: 0.6933 - val_loss: 1.8645\n",
            "Epoch 21/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6956 - loss: 1.8571 - val_accuracy: 0.7019 - val_loss: 1.8248\n",
            "Epoch 22/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7012 - loss: 1.8150 - val_accuracy: 0.7106 - val_loss: 1.7862\n",
            "Epoch 23/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7059 - loss: 1.7835 - val_accuracy: 0.7193 - val_loss: 1.7488\n",
            "Epoch 24/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7163 - loss: 1.7413 - val_accuracy: 0.7264 - val_loss: 1.7128\n",
            "Epoch 25/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7213 - loss: 1.7087 - val_accuracy: 0.7345 - val_loss: 1.6780\n",
            "Epoch 26/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7351 - loss: 1.6644 - val_accuracy: 0.7407 - val_loss: 1.6446\n",
            "Epoch 27/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7418 - loss: 1.6359 - val_accuracy: 0.7464 - val_loss: 1.6125\n",
            "Epoch 28/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7483 - loss: 1.6001 - val_accuracy: 0.7517 - val_loss: 1.5817\n",
            "Epoch 29/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7475 - loss: 1.5790 - val_accuracy: 0.7573 - val_loss: 1.5522\n",
            "Epoch 30/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7589 - loss: 1.5430 - val_accuracy: 0.7620 - val_loss: 1.5240\n",
            "Epoch 31/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7620 - loss: 1.5145 - val_accuracy: 0.7673 - val_loss: 1.4970\n",
            "Epoch 32/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7642 - loss: 1.4933 - val_accuracy: 0.7721 - val_loss: 1.4712\n",
            "Epoch 33/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7721 - loss: 1.4624 - val_accuracy: 0.7751 - val_loss: 1.4466\n",
            "Epoch 34/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7768 - loss: 1.4384 - val_accuracy: 0.7784 - val_loss: 1.4231\n",
            "Epoch 35/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7787 - loss: 1.4137 - val_accuracy: 0.7817 - val_loss: 1.4007\n",
            "Epoch 36/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7862 - loss: 1.3892 - val_accuracy: 0.7862 - val_loss: 1.3793\n",
            "Epoch 37/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7868 - loss: 1.3744 - val_accuracy: 0.7901 - val_loss: 1.3589\n",
            "Epoch 38/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7878 - loss: 1.3619 - val_accuracy: 0.7930 - val_loss: 1.3394\n",
            "Epoch 39/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7905 - loss: 1.3302 - val_accuracy: 0.7973 - val_loss: 1.3208\n",
            "Epoch 40/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7955 - loss: 1.3152 - val_accuracy: 0.8016 - val_loss: 1.3031\n",
            "Epoch 41/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7955 - loss: 1.3029 - val_accuracy: 0.8038 - val_loss: 1.2862\n",
            "Epoch 42/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7977 - loss: 1.2825 - val_accuracy: 0.8055 - val_loss: 1.2700\n",
            "Epoch 43/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8009 - loss: 1.2696 - val_accuracy: 0.8076 - val_loss: 1.2546\n",
            "Epoch 44/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8035 - loss: 1.2525 - val_accuracy: 0.8101 - val_loss: 1.2398\n",
            "Epoch 45/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8042 - loss: 1.2382 - val_accuracy: 0.8114 - val_loss: 1.2257\n",
            "Epoch 46/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8098 - loss: 1.2258 - val_accuracy: 0.8136 - val_loss: 1.2122\n",
            "Epoch 47/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 1.2125 - val_accuracy: 0.8153 - val_loss: 1.1993\n",
            "Epoch 48/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8116 - loss: 1.2000 - val_accuracy: 0.8174 - val_loss: 1.1870\n",
            "Epoch 49/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8170 - loss: 1.1835 - val_accuracy: 0.8195 - val_loss: 1.1751\n",
            "Epoch 50/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8151 - loss: 1.1719 - val_accuracy: 0.8219 - val_loss: 1.1637\n",
            "Training time for MLP task 1: 208.9672327041626 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_task1.evaluate_model(x_test, y_test)\n",
        "\n",
        "mlp_task1.summary()"
      ],
      "metadata": {
        "id": "CL7XAmkQoINl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "4ee4a1f1-7c96-46c5-c7f4-947d1e3fcd23"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8165 - loss: 1.1651\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mlp_15\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_15\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_15 (\u001b[38;5;33mSequential\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │          \u001b[38;5;34m89,610\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TASK 2"
      ],
      "metadata": {
        "id": "JZ-uOODhlqe1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make a dataframe to compare the accuracy and loss for all the different activation\n",
        "df = pd.DataFrame(columns=['Activation', 'Loss', 'Accuracy','Time'])"
      ],
      "metadata": {
        "id": "_osGE1sftky5"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sigmoid activation"
      ],
      "metadata": {
        "id": "5yqpgH_hpefB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_sigmoid = MLP(num_classes=10,\n",
        "          input_shape=(28*28,),\n",
        "          n_layers=2,\n",
        "          n_units=100,\n",
        "          activation='sigmoid',\n",
        "          optim= tf.keras.optimizers.SGD(learning_rate=0.0001),\n",
        "          loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "          initializer=tf.keras.initializers.RandomNormal(),\n",
        "          reg = tf.keras.regularizers.l2(0.001))\n",
        "mlp_sigmoid.compile_model()\n",
        "start = time.time()\n",
        "mlp_sigmoid.train_model(x_train, y_train, x_val, y_val, epochs=50, batch_size=32)\n",
        "end = time.time()\n",
        "print(f\"Training time for MLP task 2 sigmoid activation: {end - start} seconds\")\n",
        "print(\"\\n\")\n",
        "test_loss, test_acc = mlp_sigmoid.evaluate_model(x_test, y_test)\n",
        "df.loc[len(df)] =['sigmoid',test_loss, test_acc, end - start]\n",
        "mlp_sigmoid.summary()"
      ],
      "metadata": {
        "id": "re1pP1zywpnm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c73a2bff-052c-43f2-c9e9-41cea7d1a926"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.0951 - loss: 2.7572 - val_accuracy: 0.0992 - val_loss: 2.7031\n",
            "Epoch 2/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.0992 - loss: 2.6966 - val_accuracy: 0.0992 - val_loss: 2.6580\n",
            "Epoch 3/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1002 - loss: 2.6495 - val_accuracy: 0.0992 - val_loss: 2.6244\n",
            "Epoch 4/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1000 - loss: 2.6226 - val_accuracy: 0.0992 - val_loss: 2.5989\n",
            "Epoch 5/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1009 - loss: 2.5982 - val_accuracy: 0.0992 - val_loss: 2.5793\n",
            "Epoch 6/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.0985 - loss: 2.5803 - val_accuracy: 0.0992 - val_loss: 2.5642\n",
            "Epoch 7/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.0999 - loss: 2.5658 - val_accuracy: 0.0992 - val_loss: 2.5526\n",
            "Epoch 8/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.0964 - loss: 2.5525 - val_accuracy: 0.0985 - val_loss: 2.5438\n",
            "Epoch 9/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.0980 - loss: 2.5452 - val_accuracy: 0.0944 - val_loss: 2.5372\n",
            "Epoch 10/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.0919 - loss: 2.5371 - val_accuracy: 0.0859 - val_loss: 2.5323\n",
            "Epoch 11/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.0866 - loss: 2.5324 - val_accuracy: 0.0807 - val_loss: 2.5286\n",
            "Epoch 12/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.0826 - loss: 2.5293 - val_accuracy: 0.0839 - val_loss: 2.5259\n",
            "Epoch 13/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.0873 - loss: 2.5264 - val_accuracy: 0.0961 - val_loss: 2.5239\n",
            "Epoch 14/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.1015 - loss: 2.5248 - val_accuracy: 0.1066 - val_loss: 2.5224\n",
            "Epoch 15/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1105 - loss: 2.5226 - val_accuracy: 0.1137 - val_loss: 2.5213\n",
            "Epoch 16/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.1160 - loss: 2.5221 - val_accuracy: 0.1180 - val_loss: 2.5204\n",
            "Epoch 17/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1192 - loss: 2.5207 - val_accuracy: 0.1199 - val_loss: 2.5197\n",
            "Epoch 18/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1276 - loss: 2.5199 - val_accuracy: 0.1578 - val_loss: 2.5191\n",
            "Epoch 19/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1599 - loss: 2.5197 - val_accuracy: 0.1513 - val_loss: 2.5187\n",
            "Epoch 20/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1476 - loss: 2.5196 - val_accuracy: 0.1297 - val_loss: 2.5183\n",
            "Epoch 21/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1205 - loss: 2.5194 - val_accuracy: 0.1189 - val_loss: 2.5179\n",
            "Epoch 22/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.1146 - loss: 2.5185 - val_accuracy: 0.1156 - val_loss: 2.5176\n",
            "Epoch 23/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1159 - loss: 2.5180 - val_accuracy: 0.1149 - val_loss: 2.5172\n",
            "Epoch 24/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1113 - loss: 2.5178 - val_accuracy: 0.1149 - val_loss: 2.5169\n",
            "Epoch 25/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1124 - loss: 2.5171 - val_accuracy: 0.1148 - val_loss: 2.5166\n",
            "Epoch 26/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1129 - loss: 2.5168 - val_accuracy: 0.1148 - val_loss: 2.5164\n",
            "Epoch 27/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1114 - loss: 2.5169 - val_accuracy: 0.1148 - val_loss: 2.5161\n",
            "Epoch 28/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1128 - loss: 2.5162 - val_accuracy: 0.1148 - val_loss: 2.5158\n",
            "Epoch 29/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1095 - loss: 2.5167 - val_accuracy: 0.1148 - val_loss: 2.5155\n",
            "Epoch 30/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.1122 - loss: 2.5156 - val_accuracy: 0.1148 - val_loss: 2.5152\n",
            "Epoch 31/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1117 - loss: 2.5157 - val_accuracy: 0.1148 - val_loss: 2.5149\n",
            "Epoch 32/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1121 - loss: 2.5151 - val_accuracy: 0.1148 - val_loss: 2.5146\n",
            "Epoch 33/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.1124 - loss: 2.5152 - val_accuracy: 0.1148 - val_loss: 2.5144\n",
            "Epoch 34/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1126 - loss: 2.5143 - val_accuracy: 0.1148 - val_loss: 2.5141\n",
            "Epoch 35/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.1155 - loss: 2.5141 - val_accuracy: 0.1148 - val_loss: 2.5138\n",
            "Epoch 36/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1124 - loss: 2.5142 - val_accuracy: 0.1148 - val_loss: 2.5135\n",
            "Epoch 37/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1108 - loss: 2.5144 - val_accuracy: 0.1148 - val_loss: 2.5132\n",
            "Epoch 38/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1125 - loss: 2.5135 - val_accuracy: 0.1148 - val_loss: 2.5129\n",
            "Epoch 39/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1108 - loss: 2.5133 - val_accuracy: 0.1148 - val_loss: 2.5126\n",
            "Epoch 40/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1103 - loss: 2.5135 - val_accuracy: 0.1148 - val_loss: 2.5124\n",
            "Epoch 41/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1121 - loss: 2.5130 - val_accuracy: 0.1148 - val_loss: 2.5121\n",
            "Epoch 42/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.1136 - loss: 2.5125 - val_accuracy: 0.1148 - val_loss: 2.5118\n",
            "Epoch 43/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1113 - loss: 2.5124 - val_accuracy: 0.1148 - val_loss: 2.5115\n",
            "Epoch 44/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1119 - loss: 2.5117 - val_accuracy: 0.1148 - val_loss: 2.5112\n",
            "Epoch 45/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1103 - loss: 2.5116 - val_accuracy: 0.1148 - val_loss: 2.5109\n",
            "Epoch 46/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1122 - loss: 2.5115 - val_accuracy: 0.1148 - val_loss: 2.5106\n",
            "Epoch 47/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.1139 - loss: 2.5106 - val_accuracy: 0.1148 - val_loss: 2.5103\n",
            "Epoch 48/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1106 - loss: 2.5111 - val_accuracy: 0.1148 - val_loss: 2.5101\n",
            "Epoch 49/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1098 - loss: 2.5108 - val_accuracy: 0.1148 - val_loss: 2.5098\n",
            "Epoch 50/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1105 - loss: 2.5104 - val_accuracy: 0.1148 - val_loss: 2.5095\n",
            "Training time for MLP task 2 sigmoid activation: 231.94738125801086 seconds\n",
            "\n",
            "\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1121 - loss: 2.5101\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mlp_16\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_16\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_16 (\u001b[38;5;33mSequential\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │          \u001b[38;5;34m89,610\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tanh activation"
      ],
      "metadata": {
        "id": "CukRJVknppma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_tanh = MLP(num_classes=10,\n",
        "          input_shape=(28*28,),\n",
        "          n_layers=2,\n",
        "          n_units=100,\n",
        "          activation='tanh',\n",
        "          optim= tf.keras.optimizers.SGD(learning_rate=0.0001),\n",
        "          loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "          initializer=tf.keras.initializers.RandomNormal(),\n",
        "          reg = tf.keras.regularizers.l2(0.001))\n",
        "mlp_tanh.compile_model()\n",
        "start = time.time()\n",
        "mlp_tanh.train_model(x_train, y_train, x_val, y_val, epochs=50, batch_size=32)\n",
        "end = time.time()\n",
        "print(f\"Training time for MLP task 2 tanh activation: {end - start} seconds\")\n",
        "print(\"\\n\")\n",
        "test_loss, test_acc = mlp_tanh.evaluate_model(x_test, y_test)\n",
        "df.loc[len(df)] =['tanh',test_loss, test_acc, end - start]\n",
        "mlp_tanh.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ojk9trllpo--",
        "outputId": "72f561ec-726d-41fc-b680-caa79772d606"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.1057 - loss: 2.5444 - val_accuracy: 0.1479 - val_loss: 2.5128\n",
            "Epoch 2/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.1636 - loss: 2.5003 - val_accuracy: 0.2092 - val_loss: 2.4695\n",
            "Epoch 3/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2296 - loss: 2.4568 - val_accuracy: 0.2680 - val_loss: 2.4279\n",
            "Epoch 4/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2797 - loss: 2.4155 - val_accuracy: 0.3184 - val_loss: 2.3875\n",
            "Epoch 5/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3277 - loss: 2.3753 - val_accuracy: 0.3596 - val_loss: 2.3482\n",
            "Epoch 6/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3692 - loss: 2.3381 - val_accuracy: 0.4065 - val_loss: 2.3097\n",
            "Epoch 7/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4127 - loss: 2.2978 - val_accuracy: 0.4517 - val_loss: 2.2718\n",
            "Epoch 8/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4554 - loss: 2.2636 - val_accuracy: 0.4963 - val_loss: 2.2346\n",
            "Epoch 9/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5002 - loss: 2.2253 - val_accuracy: 0.5392 - val_loss: 2.1978\n",
            "Epoch 10/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5450 - loss: 2.1884 - val_accuracy: 0.5773 - val_loss: 2.1615\n",
            "Epoch 11/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5786 - loss: 2.1533 - val_accuracy: 0.6051 - val_loss: 2.1255\n",
            "Epoch 12/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6068 - loss: 2.1173 - val_accuracy: 0.6268 - val_loss: 2.0899\n",
            "Epoch 13/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6326 - loss: 2.0812 - val_accuracy: 0.6482 - val_loss: 2.0547\n",
            "Epoch 14/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6496 - loss: 2.0457 - val_accuracy: 0.6624 - val_loss: 2.0199\n",
            "Epoch 15/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6619 - loss: 2.0112 - val_accuracy: 0.6732 - val_loss: 1.9855\n",
            "Epoch 16/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6728 - loss: 1.9751 - val_accuracy: 0.6824 - val_loss: 1.9515\n",
            "Epoch 17/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6788 - loss: 1.9459 - val_accuracy: 0.6913 - val_loss: 1.9179\n",
            "Epoch 18/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6864 - loss: 1.9136 - val_accuracy: 0.6999 - val_loss: 1.8848\n",
            "Epoch 19/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6977 - loss: 1.8773 - val_accuracy: 0.7073 - val_loss: 1.8523\n",
            "Epoch 20/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7017 - loss: 1.8465 - val_accuracy: 0.7136 - val_loss: 1.8203\n",
            "Epoch 21/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7106 - loss: 1.8153 - val_accuracy: 0.7203 - val_loss: 1.7888\n",
            "Epoch 22/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7131 - loss: 1.7855 - val_accuracy: 0.7265 - val_loss: 1.7580\n",
            "Epoch 23/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7212 - loss: 1.7532 - val_accuracy: 0.7313 - val_loss: 1.7279\n",
            "Epoch 24/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7253 - loss: 1.7230 - val_accuracy: 0.7362 - val_loss: 1.6984\n",
            "Epoch 25/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7323 - loss: 1.6936 - val_accuracy: 0.7406 - val_loss: 1.6696\n",
            "Epoch 26/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7353 - loss: 1.6643 - val_accuracy: 0.7456 - val_loss: 1.6415\n",
            "Epoch 27/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7387 - loss: 1.6379 - val_accuracy: 0.7507 - val_loss: 1.6142\n",
            "Epoch 28/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7415 - loss: 1.6101 - val_accuracy: 0.7542 - val_loss: 1.5876\n",
            "Epoch 29/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7456 - loss: 1.5799 - val_accuracy: 0.7586 - val_loss: 1.5618\n",
            "Epoch 30/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7509 - loss: 1.5559 - val_accuracy: 0.7624 - val_loss: 1.5367\n",
            "Epoch 31/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7529 - loss: 1.5337 - val_accuracy: 0.7643 - val_loss: 1.5124\n",
            "Epoch 32/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7508 - loss: 1.5119 - val_accuracy: 0.7677 - val_loss: 1.4888\n",
            "Epoch 33/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7553 - loss: 1.4902 - val_accuracy: 0.7697 - val_loss: 1.4660\n",
            "Epoch 34/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7623 - loss: 1.4634 - val_accuracy: 0.7727 - val_loss: 1.4439\n",
            "Epoch 35/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7650 - loss: 1.4440 - val_accuracy: 0.7749 - val_loss: 1.4225\n",
            "Epoch 36/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7660 - loss: 1.4248 - val_accuracy: 0.7767 - val_loss: 1.4018\n",
            "Epoch 37/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7707 - loss: 1.4002 - val_accuracy: 0.7800 - val_loss: 1.3818\n",
            "Epoch 38/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7732 - loss: 1.3812 - val_accuracy: 0.7822 - val_loss: 1.3625\n",
            "Epoch 39/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7748 - loss: 1.3664 - val_accuracy: 0.7846 - val_loss: 1.3438\n",
            "Epoch 40/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7775 - loss: 1.3408 - val_accuracy: 0.7878 - val_loss: 1.3258\n",
            "Epoch 41/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7784 - loss: 1.3303 - val_accuracy: 0.7897 - val_loss: 1.3083\n",
            "Epoch 42/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7833 - loss: 1.3097 - val_accuracy: 0.7912 - val_loss: 1.2915\n",
            "Epoch 43/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7866 - loss: 1.2900 - val_accuracy: 0.7937 - val_loss: 1.2752\n",
            "Epoch 44/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7876 - loss: 1.2742 - val_accuracy: 0.7952 - val_loss: 1.2595\n",
            "Epoch 45/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7908 - loss: 1.2555 - val_accuracy: 0.7981 - val_loss: 1.2443\n",
            "Epoch 46/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7938 - loss: 1.2420 - val_accuracy: 0.7997 - val_loss: 1.2296\n",
            "Epoch 47/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7935 - loss: 1.2319 - val_accuracy: 0.8013 - val_loss: 1.2154\n",
            "Epoch 48/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7954 - loss: 1.2183 - val_accuracy: 0.8040 - val_loss: 1.2016\n",
            "Epoch 49/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7989 - loss: 1.1975 - val_accuracy: 0.8058 - val_loss: 1.1883\n",
            "Epoch 50/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7998 - loss: 1.1926 - val_accuracy: 0.8071 - val_loss: 1.1755\n",
            "Training time for MLP task 2 tanh activation: 200.745210647583 seconds\n",
            "\n",
            "\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7954 - loss: 1.1792\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mlp_17\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_17\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_17 (\u001b[38;5;33mSequential\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │          \u001b[38;5;34m89,610\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relu activation"
      ],
      "metadata": {
        "id": "Z1oZQfkdqke_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_relu = MLP(num_classes=10,\n",
        "          input_shape=(28*28,),\n",
        "          n_layers=2,\n",
        "          n_units=100,\n",
        "          activation='relu',\n",
        "          optim= tf.keras.optimizers.SGD(learning_rate=0.0001),\n",
        "          loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "          initializer=tf.keras.initializers.RandomNormal(),\n",
        "          reg = tf.keras.regularizers.l2(0.001))\n",
        "mlp_relu.compile_model()\n",
        "start = time.time()\n",
        "mlp_relu.train_model(x_train, y_train, x_val, y_val, epochs=50, batch_size=32)\n",
        "end = time.time()\n",
        "print(f\"Training time for MLP task 2 relu activation: {end - start} seconds\")\n",
        "print(\"\\n\")\n",
        "test_loss, test_acc = mlp_relu.evaluate_model(x_test, y_test)\n",
        "df.loc[len(df)] =['relu',test_loss, test_acc,end - start]\n",
        "mlp_relu.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O4mTbjNrqjqc",
        "outputId": "0492f3d3-70e0-4527-f549-4144ad400505"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1249 - loss: 2.5237 - val_accuracy: 0.1382 - val_loss: 2.5134\n",
            "Epoch 2/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1426 - loss: 2.5091 - val_accuracy: 0.1565 - val_loss: 2.4986\n",
            "Epoch 3/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1632 - loss: 2.4949 - val_accuracy: 0.1777 - val_loss: 2.4842\n",
            "Epoch 4/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1803 - loss: 2.4811 - val_accuracy: 0.2016 - val_loss: 2.4701\n",
            "Epoch 5/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2054 - loss: 2.4655 - val_accuracy: 0.2276 - val_loss: 2.4561\n",
            "Epoch 6/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2295 - loss: 2.4525 - val_accuracy: 0.2520 - val_loss: 2.4423\n",
            "Epoch 7/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.2523 - loss: 2.4392 - val_accuracy: 0.2756 - val_loss: 2.4286\n",
            "Epoch 8/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2726 - loss: 2.4258 - val_accuracy: 0.2966 - val_loss: 2.4148\n",
            "Epoch 9/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2995 - loss: 2.4108 - val_accuracy: 0.3161 - val_loss: 2.4008\n",
            "Epoch 10/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3229 - loss: 2.3958 - val_accuracy: 0.3348 - val_loss: 2.3867\n",
            "Epoch 11/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3428 - loss: 2.3826 - val_accuracy: 0.3551 - val_loss: 2.3722\n",
            "Epoch 12/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3640 - loss: 2.3663 - val_accuracy: 0.3751 - val_loss: 2.3574\n",
            "Epoch 13/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3841 - loss: 2.3519 - val_accuracy: 0.3960 - val_loss: 2.3422\n",
            "Epoch 14/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4007 - loss: 2.3372 - val_accuracy: 0.4135 - val_loss: 2.3266\n",
            "Epoch 15/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4192 - loss: 2.3209 - val_accuracy: 0.4317 - val_loss: 2.3104\n",
            "Epoch 16/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4399 - loss: 2.3056 - val_accuracy: 0.4510 - val_loss: 2.2937\n",
            "Epoch 17/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4527 - loss: 2.2894 - val_accuracy: 0.4652 - val_loss: 2.2765\n",
            "Epoch 18/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4695 - loss: 2.2701 - val_accuracy: 0.4797 - val_loss: 2.2588\n",
            "Epoch 19/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4811 - loss: 2.2534 - val_accuracy: 0.4951 - val_loss: 2.2404\n",
            "Epoch 20/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4991 - loss: 2.2335 - val_accuracy: 0.5078 - val_loss: 2.2215\n",
            "Epoch 21/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5165 - loss: 2.2142 - val_accuracy: 0.5215 - val_loss: 2.2019\n",
            "Epoch 22/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5315 - loss: 2.1949 - val_accuracy: 0.5356 - val_loss: 2.1817\n",
            "Epoch 23/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5358 - loss: 2.1764 - val_accuracy: 0.5481 - val_loss: 2.1609\n",
            "Epoch 24/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5501 - loss: 2.1562 - val_accuracy: 0.5586 - val_loss: 2.1396\n",
            "Epoch 25/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5637 - loss: 2.1300 - val_accuracy: 0.5688 - val_loss: 2.1176\n",
            "Epoch 26/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5686 - loss: 2.1124 - val_accuracy: 0.5806 - val_loss: 2.0951\n",
            "Epoch 27/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5772 - loss: 2.0897 - val_accuracy: 0.5909 - val_loss: 2.0722\n",
            "Epoch 28/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5896 - loss: 2.0666 - val_accuracy: 0.6006 - val_loss: 2.0488\n",
            "Epoch 29/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5962 - loss: 2.0416 - val_accuracy: 0.6097 - val_loss: 2.0250\n",
            "Epoch 30/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6083 - loss: 2.0192 - val_accuracy: 0.6197 - val_loss: 2.0009\n",
            "Epoch 31/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6155 - loss: 1.9944 - val_accuracy: 0.6285 - val_loss: 1.9765\n",
            "Epoch 32/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6262 - loss: 1.9691 - val_accuracy: 0.6367 - val_loss: 1.9518\n",
            "Epoch 33/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6369 - loss: 1.9440 - val_accuracy: 0.6452 - val_loss: 1.9269\n",
            "Epoch 34/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6438 - loss: 1.9206 - val_accuracy: 0.6545 - val_loss: 1.9018\n",
            "Epoch 35/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6498 - loss: 1.8946 - val_accuracy: 0.6610 - val_loss: 1.8766\n",
            "Epoch 36/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6603 - loss: 1.8703 - val_accuracy: 0.6701 - val_loss: 1.8512\n",
            "Epoch 37/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6665 - loss: 1.8458 - val_accuracy: 0.6791 - val_loss: 1.8257\n",
            "Epoch 38/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.6809 - loss: 1.8160 - val_accuracy: 0.6889 - val_loss: 1.8002\n",
            "Epoch 39/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6859 - loss: 1.7946 - val_accuracy: 0.6958 - val_loss: 1.7747\n",
            "Epoch 40/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6979 - loss: 1.7673 - val_accuracy: 0.7042 - val_loss: 1.7493\n",
            "Epoch 41/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7035 - loss: 1.7465 - val_accuracy: 0.7126 - val_loss: 1.7239\n",
            "Epoch 42/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7056 - loss: 1.7215 - val_accuracy: 0.7216 - val_loss: 1.6987\n",
            "Epoch 43/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7128 - loss: 1.6947 - val_accuracy: 0.7263 - val_loss: 1.6736\n",
            "Epoch 44/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7226 - loss: 1.6700 - val_accuracy: 0.7312 - val_loss: 1.6488\n",
            "Epoch 45/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7277 - loss: 1.6451 - val_accuracy: 0.7354 - val_loss: 1.6242\n",
            "Epoch 46/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7337 - loss: 1.6218 - val_accuracy: 0.7402 - val_loss: 1.5999\n",
            "Epoch 47/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7422 - loss: 1.5938 - val_accuracy: 0.7451 - val_loss: 1.5759\n",
            "Epoch 48/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7494 - loss: 1.5708 - val_accuracy: 0.7501 - val_loss: 1.5522\n",
            "Epoch 49/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7481 - loss: 1.5487 - val_accuracy: 0.7542 - val_loss: 1.5290\n",
            "Epoch 50/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7566 - loss: 1.5187 - val_accuracy: 0.7581 - val_loss: 1.5061\n",
            "Training time for MLP task 2 relu activation: 213.75373125076294 seconds\n",
            "\n",
            "\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7522 - loss: 1.5118\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mlp_18\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_18\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_18 (\u001b[38;5;33mSequential\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │          \u001b[38;5;34m89,610\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare the accuracy, loss, time for all the different activation"
      ],
      "metadata": {
        "id": "nmHj2Nrv-Rmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV3rvMFG6RTm",
        "outputId": "02b70670-5cc9-4ab2-d385-981b6ca7178a"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Activation      Loss  Accuracy        Time\n",
            "0    sigmoid  2.509926  0.112571  231.947381\n",
            "1       tanh  1.179146  0.798476  200.745211\n",
            "2       relu  1.511621  0.753190  213.753731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results: Activation = tanh, has the least amount of loss and highest accuracy. But the fastest time varies, sometimes its tanh and other times it is relu. My last fastest time is relu."
      ],
      "metadata": {
        "id": "P1KzPDXB_r4Y"
      }
    }
  ]
}