{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fiona Nicdao's Assignment 2"
      ],
      "metadata": {
        "id": "9Z7bfcTTtV8d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vm2lOB5Zdo3y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import  keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing the MNIST Dataset"
      ],
      "metadata": {
        "id": "PofcRAbftNVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#build the model based on the data\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Change the data to be split into 70% training set and 30% testing set\n",
        "x = np.concatenate((x_train, x_test))\n",
        "y = np.concatenate((y_train, y_test))\n",
        "train_size = 0.7\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=train_size,\n",
        "                                                    random_state=42)\n",
        "\n",
        "dev_size = 0.8 * x_train.shape[0]\n",
        "dev_size = int(dev_size)\n",
        "\n",
        "#shuffle the x_train (good practice)\n",
        "#seed for reproducibility\n",
        "indices = np.arange(x_train.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "x_train = x_train[indices]\n",
        "y_train = y_train[indices]\n",
        "\n",
        "# plot the image\n",
        "plt.imshow(x_train[0], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "#dividing the training dataset into 80/20 : training set/ validation set\n",
        "x_val = x_train[dev_size:] #validation sets\n",
        "y_val = y_train[dev_size:]\n",
        "\n",
        "x_train = x_train[:dev_size] #training sets\n",
        "y_train = y_train[:dev_size]\n",
        "\n",
        "#preparing training data\n",
        "#dividing them by max pixel value as a float to get all values btw 0 and 1\n",
        "x_train = (x_train/255.0).reshape(-1, 28*28)\n",
        "x_val = (x_val/255.0).reshape(-1, 28*28)\n",
        "x_test = (x_test/255.0).reshape(-1, 28*28)\n",
        "\n",
        "#make the classes one-hot encodings\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_val = tf.keras.utils.to_categorical(y_val)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "print(x_train.shape) #6000 training samples, image is 28x28 size\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n"
      ],
      "metadata": {
        "id": "yEuwjCr1piTb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "0353fabc-e3fd-4c02-c047-e99707103fb5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(39200, 784)\n",
            "(39200, 10)\n",
            "(21000, 784)\n",
            "(21000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check step that the data is normalized between [1.0, 0.0]\n",
        "x_train[0].max(), x_train[0].min()\n",
        "# better to have it float values /"
      ],
      "metadata": {
        "id": "AttxEG5XfaLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d49210e-d24c-4544-8b52-70fbfabc4514"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Model : MLP"
      ],
      "metadata": {
        "id": "wxNuwLkitDyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model\n",
        "class MLP(tf.keras.Model):\n",
        "  def __init__(self, num_classes, input_shape, n_layers, n_units, activation,\n",
        "               optim, loss, initializer,reg):\n",
        "      super(MLP, self).__init__()\n",
        "      self.num_classes = num_classes\n",
        "      self.input_shape = input_shape\n",
        "      self.n_layers = n_layers\n",
        "      self.n_units = n_units\n",
        "      self.activation = activation\n",
        "      self.optimizer = optim\n",
        "      self.loss = loss\n",
        "      self.initializer = initializer\n",
        "      self.regularizer = reg\n",
        "\n",
        "      self.model = self.create_model()\n",
        "\n",
        "  #build the structure of the model\n",
        "  def create_model(self):\n",
        "    model = tf.keras.Sequential() # Sequential model is just a placeholder\n",
        "    model.add(tf.keras.layers.Input(shape=self.input_shape))\n",
        "\n",
        "    for i in range(self.n_layers):\n",
        "      model.add(tf.keras.layers.Dense(self.n_units,\n",
        "                                      input_shape=self.input_shape,\n",
        "                                      activation=self.activation,\n",
        "                                      kernel_initializer = self.initializer,\n",
        "                                      kernel_regularizer= self.regularizer))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(self.num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "  def compile_model(self):\n",
        "    self.model.compile(optimizer=self.optimizer, loss=self.loss,\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "  def train_model(self, x_train, y_train, x_val, y_val, epochs=10,\n",
        "                  batch_size=32):\n",
        "    self.model.fit(x_train, y_train, epochs=epochs, batch_size=64,\n",
        "                   validation_data=(x_val, y_val))\n",
        "\n",
        "  def evaluate_model(self, x_test, y_test):\n",
        "    test_loss, test_acc = self.model.evaluate(x_test, y_test)\n",
        "    return test_loss, test_acc"
      ],
      "metadata": {
        "id": "94glye77k4NJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1\n",
        "## compare the performance of 2-layer vs 3-layer vs 4-layer MLPs on MNIST dataset\n"
      ],
      "metadata": {
        "id": "cT8hjqhOrFpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make a dataframe to compare the accuracy and loss for all the different activation\n",
        "df = pd.DataFrame(columns=['Number of Layers', 'Loss', 'Accuracy','Time'])\n",
        "df['Number of Layers'] = df['Number of Layers'].astype(np.int32)"
      ],
      "metadata": {
        "id": "TZfXdEb1sem2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [2, 3, 4]\n",
        "for layer in layers:\n",
        "  mlp_layer = MLP(num_classes=10,\n",
        "            input_shape=(28*28,),\n",
        "            n_layers=layer,\n",
        "            n_units=100,\n",
        "            activation='relu',\n",
        "            optim= tf.keras.optimizers.Adam(learning_rate=0.0002),\n",
        "            loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "            initializer=tf.keras.initializers.RandomNormal(),\n",
        "            reg = tf.keras.regularizers.l2(0.001))\n",
        "  mlp_layer.compile_model()\n",
        "  start = time.time()\n",
        "  mlp_layer.train_model(x_train, y_train, x_val, y_val, epochs=50, batch_size=32)\n",
        "  end = time.time()\n",
        "  print(f\"Training time for MLP {layer}-layer : {end - start} seconds\")\n",
        "  test_loss, test_acc = mlp_layer.evaluate_model(x_test, y_test)\n",
        "  df.loc[len(df)] = [layer, test_loss, test_acc, end - start]\n",
        "  mlp_layer.summary()"
      ],
      "metadata": {
        "id": "tDRn2D_inklo",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b9ba56fd-4d19-4c60-a5ad-897e753d024c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.6814 - loss: 1.3749 - val_accuracy: 0.9048 - val_loss: 0.4714\n",
            "Epoch 2/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9173 - loss: 0.4341 - val_accuracy: 0.9283 - val_loss: 0.3835\n",
            "Epoch 3/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9333 - loss: 0.3576 - val_accuracy: 0.9367 - val_loss: 0.3419\n",
            "Epoch 4/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9426 - loss: 0.3217 - val_accuracy: 0.9450 - val_loss: 0.3131\n",
            "Epoch 5/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9496 - loss: 0.2905 - val_accuracy: 0.9470 - val_loss: 0.2953\n",
            "Epoch 6/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9535 - loss: 0.2714 - val_accuracy: 0.9497 - val_loss: 0.2780\n",
            "Epoch 7/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9607 - loss: 0.2483 - val_accuracy: 0.9532 - val_loss: 0.2664\n",
            "Epoch 8/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9639 - loss: 0.2349 - val_accuracy: 0.9535 - val_loss: 0.2572\n",
            "Epoch 9/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9658 - loss: 0.2189 - val_accuracy: 0.9574 - val_loss: 0.2426\n",
            "Epoch 10/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9683 - loss: 0.2088 - val_accuracy: 0.9588 - val_loss: 0.2350\n",
            "Epoch 11/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9689 - loss: 0.2030 - val_accuracy: 0.9584 - val_loss: 0.2343\n",
            "Epoch 12/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9725 - loss: 0.1947 - val_accuracy: 0.9607 - val_loss: 0.2257\n",
            "Epoch 13/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9741 - loss: 0.1843 - val_accuracy: 0.9632 - val_loss: 0.2172\n",
            "Epoch 14/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9768 - loss: 0.1790 - val_accuracy: 0.9626 - val_loss: 0.2129\n",
            "Epoch 15/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9780 - loss: 0.1720 - val_accuracy: 0.9631 - val_loss: 0.2117\n",
            "Epoch 16/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9787 - loss: 0.1673 - val_accuracy: 0.9643 - val_loss: 0.2045\n",
            "Epoch 17/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9784 - loss: 0.1647 - val_accuracy: 0.9651 - val_loss: 0.1969\n",
            "Epoch 18/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9801 - loss: 0.1591 - val_accuracy: 0.9656 - val_loss: 0.1946\n",
            "Epoch 19/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9809 - loss: 0.1546 - val_accuracy: 0.9676 - val_loss: 0.1905\n",
            "Epoch 20/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9816 - loss: 0.1513 - val_accuracy: 0.9677 - val_loss: 0.1871\n",
            "Epoch 21/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9831 - loss: 0.1463 - val_accuracy: 0.9673 - val_loss: 0.1875\n",
            "Epoch 22/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9838 - loss: 0.1447 - val_accuracy: 0.9687 - val_loss: 0.1818\n",
            "Epoch 23/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9850 - loss: 0.1402 - val_accuracy: 0.9694 - val_loss: 0.1791\n",
            "Epoch 24/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9859 - loss: 0.1369 - val_accuracy: 0.9696 - val_loss: 0.1788\n",
            "Epoch 25/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9860 - loss: 0.1340 - val_accuracy: 0.9702 - val_loss: 0.1763\n",
            "Epoch 26/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9871 - loss: 0.1299 - val_accuracy: 0.9702 - val_loss: 0.1759\n",
            "Epoch 27/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9877 - loss: 0.1294 - val_accuracy: 0.9716 - val_loss: 0.1719\n",
            "Epoch 28/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9866 - loss: 0.1282 - val_accuracy: 0.9730 - val_loss: 0.1708\n",
            "Epoch 29/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9874 - loss: 0.1264 - val_accuracy: 0.9716 - val_loss: 0.1693\n",
            "Epoch 30/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9877 - loss: 0.1254 - val_accuracy: 0.9708 - val_loss: 0.1690\n",
            "Epoch 31/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9889 - loss: 0.1210 - val_accuracy: 0.9719 - val_loss: 0.1667\n",
            "Epoch 32/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9890 - loss: 0.1198 - val_accuracy: 0.9715 - val_loss: 0.1649\n",
            "Epoch 33/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9897 - loss: 0.1169 - val_accuracy: 0.9732 - val_loss: 0.1638\n",
            "Epoch 34/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9899 - loss: 0.1142 - val_accuracy: 0.9709 - val_loss: 0.1663\n",
            "Epoch 35/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9896 - loss: 0.1143 - val_accuracy: 0.9699 - val_loss: 0.1689\n",
            "Epoch 36/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9901 - loss: 0.1124 - val_accuracy: 0.9717 - val_loss: 0.1626\n",
            "Epoch 37/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9916 - loss: 0.1099 - val_accuracy: 0.9712 - val_loss: 0.1646\n",
            "Epoch 38/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9907 - loss: 0.1090 - val_accuracy: 0.9731 - val_loss: 0.1584\n",
            "Epoch 39/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9920 - loss: 0.1066 - val_accuracy: 0.9740 - val_loss: 0.1550\n",
            "Epoch 40/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9913 - loss: 0.1081 - val_accuracy: 0.9732 - val_loss: 0.1547\n",
            "Epoch 41/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9915 - loss: 0.1051 - val_accuracy: 0.9739 - val_loss: 0.1553\n",
            "Epoch 42/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9921 - loss: 0.1040 - val_accuracy: 0.9745 - val_loss: 0.1540\n",
            "Epoch 43/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9928 - loss: 0.1012 - val_accuracy: 0.9737 - val_loss: 0.1538\n",
            "Epoch 44/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9923 - loss: 0.1023 - val_accuracy: 0.9753 - val_loss: 0.1528\n",
            "Epoch 45/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9936 - loss: 0.0999 - val_accuracy: 0.9734 - val_loss: 0.1505\n",
            "Epoch 46/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9928 - loss: 0.0996 - val_accuracy: 0.9730 - val_loss: 0.1505\n",
            "Epoch 47/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9931 - loss: 0.0984 - val_accuracy: 0.9737 - val_loss: 0.1498\n",
            "Epoch 48/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.0970 - val_accuracy: 0.9734 - val_loss: 0.1495\n",
            "Epoch 49/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9938 - loss: 0.0954 - val_accuracy: 0.9740 - val_loss: 0.1487\n",
            "Epoch 50/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9934 - loss: 0.0943 - val_accuracy: 0.9735 - val_loss: 0.1484\n",
            "Training time for MLP 2-layer : 222.5398952960968 seconds\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9728 - loss: 0.1493\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mlp\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential (\u001b[38;5;33mSequential\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │          \u001b[38;5;34m89,610\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6558 - loss: 1.4571 - val_accuracy: 0.9034 - val_loss: 0.4963\n",
            "Epoch 2/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9133 - loss: 0.4658 - val_accuracy: 0.9232 - val_loss: 0.4101\n",
            "Epoch 3/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9333 - loss: 0.3832 - val_accuracy: 0.9334 - val_loss: 0.3684\n",
            "Epoch 4/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9428 - loss: 0.3383 - val_accuracy: 0.9436 - val_loss: 0.3336\n",
            "Epoch 5/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9528 - loss: 0.3051 - val_accuracy: 0.9453 - val_loss: 0.3178\n",
            "Epoch 6/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9555 - loss: 0.2829 - val_accuracy: 0.9491 - val_loss: 0.2950\n",
            "Epoch 7/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9635 - loss: 0.2574 - val_accuracy: 0.9526 - val_loss: 0.2837\n",
            "Epoch 8/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9646 - loss: 0.2457 - val_accuracy: 0.9562 - val_loss: 0.2654\n",
            "Epoch 9/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9668 - loss: 0.2325 - val_accuracy: 0.9601 - val_loss: 0.2547\n",
            "Epoch 10/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9716 - loss: 0.2204 - val_accuracy: 0.9568 - val_loss: 0.2590\n",
            "Epoch 11/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9727 - loss: 0.2074 - val_accuracy: 0.9622 - val_loss: 0.2355\n",
            "Epoch 12/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9751 - loss: 0.2027 - val_accuracy: 0.9642 - val_loss: 0.2311\n",
            "Epoch 13/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9767 - loss: 0.1934 - val_accuracy: 0.9637 - val_loss: 0.2307\n",
            "Epoch 14/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9800 - loss: 0.1842 - val_accuracy: 0.9663 - val_loss: 0.2191\n",
            "Epoch 15/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9810 - loss: 0.1775 - val_accuracy: 0.9654 - val_loss: 0.2166\n",
            "Epoch 16/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9818 - loss: 0.1727 - val_accuracy: 0.9667 - val_loss: 0.2153\n",
            "Epoch 17/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9813 - loss: 0.1709 - val_accuracy: 0.9658 - val_loss: 0.2145\n",
            "Epoch 18/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9825 - loss: 0.1632 - val_accuracy: 0.9647 - val_loss: 0.2124\n",
            "Epoch 19/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9853 - loss: 0.1573 - val_accuracy: 0.9685 - val_loss: 0.2029\n",
            "Epoch 20/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9859 - loss: 0.1542 - val_accuracy: 0.9709 - val_loss: 0.1983\n",
            "Epoch 21/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9870 - loss: 0.1504 - val_accuracy: 0.9671 - val_loss: 0.2051\n",
            "Epoch 22/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9844 - loss: 0.1509 - val_accuracy: 0.9695 - val_loss: 0.1978\n",
            "Epoch 23/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9866 - loss: 0.1455 - val_accuracy: 0.9672 - val_loss: 0.1962\n",
            "Epoch 24/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9874 - loss: 0.1423 - val_accuracy: 0.9669 - val_loss: 0.2000\n",
            "Epoch 25/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9875 - loss: 0.1400 - val_accuracy: 0.9714 - val_loss: 0.1869\n",
            "Epoch 26/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9877 - loss: 0.1372 - val_accuracy: 0.9717 - val_loss: 0.1866\n",
            "Epoch 27/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9896 - loss: 0.1338 - val_accuracy: 0.9732 - val_loss: 0.1887\n",
            "Epoch 28/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9892 - loss: 0.1311 - val_accuracy: 0.9699 - val_loss: 0.1926\n",
            "Epoch 29/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9895 - loss: 0.1317 - val_accuracy: 0.9716 - val_loss: 0.1858\n",
            "Epoch 30/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9901 - loss: 0.1269 - val_accuracy: 0.9711 - val_loss: 0.1809\n",
            "Epoch 31/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9914 - loss: 0.1247 - val_accuracy: 0.9739 - val_loss: 0.1779\n",
            "Epoch 32/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9915 - loss: 0.1238 - val_accuracy: 0.9699 - val_loss: 0.1836\n",
            "Epoch 33/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9917 - loss: 0.1201 - val_accuracy: 0.9671 - val_loss: 0.1882\n",
            "Epoch 34/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9915 - loss: 0.1197 - val_accuracy: 0.9715 - val_loss: 0.1771\n",
            "Epoch 35/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.1173 - val_accuracy: 0.9740 - val_loss: 0.1726\n",
            "Epoch 36/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.1152 - val_accuracy: 0.9703 - val_loss: 0.1787\n",
            "Epoch 37/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9931 - loss: 0.1137 - val_accuracy: 0.9720 - val_loss: 0.1744\n",
            "Epoch 38/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9929 - loss: 0.1132 - val_accuracy: 0.9717 - val_loss: 0.1756\n",
            "Epoch 39/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9938 - loss: 0.1100 - val_accuracy: 0.9707 - val_loss: 0.1765\n",
            "Epoch 40/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9942 - loss: 0.1091 - val_accuracy: 0.9720 - val_loss: 0.1715\n",
            "Epoch 41/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9937 - loss: 0.1083 - val_accuracy: 0.9723 - val_loss: 0.1692\n",
            "Epoch 42/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9942 - loss: 0.1079 - val_accuracy: 0.9730 - val_loss: 0.1702\n",
            "Epoch 43/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9925 - loss: 0.1078 - val_accuracy: 0.9741 - val_loss: 0.1665\n",
            "Epoch 44/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9941 - loss: 0.1049 - val_accuracy: 0.9701 - val_loss: 0.1731\n",
            "Epoch 45/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9937 - loss: 0.1043 - val_accuracy: 0.9708 - val_loss: 0.1719\n",
            "Epoch 46/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9947 - loss: 0.1030 - val_accuracy: 0.9726 - val_loss: 0.1684\n",
            "Epoch 47/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9945 - loss: 0.1013 - val_accuracy: 0.9673 - val_loss: 0.1884\n",
            "Epoch 48/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9940 - loss: 0.1031 - val_accuracy: 0.9707 - val_loss: 0.1684\n",
            "Epoch 49/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9950 - loss: 0.0986 - val_accuracy: 0.9712 - val_loss: 0.1690\n",
            "Epoch 50/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9954 - loss: 0.0982 - val_accuracy: 0.9731 - val_loss: 0.1607\n",
            "Training time for MLP 3-layer : 221.92547702789307 seconds\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9723 - loss: 0.1642\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mlp_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_1 (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │          \u001b[38;5;34m99,710\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">99,710</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m99,710\u001b[0m (389.49 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,710</span> (389.49 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m99,710\u001b[0m (389.49 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,710</span> (389.49 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.6260 - loss: 1.5165 - val_accuracy: 0.8962 - val_loss: 0.5474\n",
            "Epoch 2/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9102 - loss: 0.4913 - val_accuracy: 0.9224 - val_loss: 0.4422\n",
            "Epoch 3/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9306 - loss: 0.4127 - val_accuracy: 0.9315 - val_loss: 0.3979\n",
            "Epoch 4/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9419 - loss: 0.3628 - val_accuracy: 0.9410 - val_loss: 0.3564\n",
            "Epoch 5/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9529 - loss: 0.3189 - val_accuracy: 0.9455 - val_loss: 0.3365\n",
            "Epoch 6/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9599 - loss: 0.2927 - val_accuracy: 0.9537 - val_loss: 0.3049\n",
            "Epoch 7/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9642 - loss: 0.2712 - val_accuracy: 0.9536 - val_loss: 0.2980\n",
            "Epoch 8/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9676 - loss: 0.2543 - val_accuracy: 0.9598 - val_loss: 0.2800\n",
            "Epoch 9/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9695 - loss: 0.2442 - val_accuracy: 0.9616 - val_loss: 0.2667\n",
            "Epoch 10/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9755 - loss: 0.2243 - val_accuracy: 0.9623 - val_loss: 0.2575\n",
            "Epoch 11/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9755 - loss: 0.2158 - val_accuracy: 0.9635 - val_loss: 0.2548\n",
            "Epoch 12/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9779 - loss: 0.2081 - val_accuracy: 0.9597 - val_loss: 0.2632\n",
            "Epoch 13/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9779 - loss: 0.2010 - val_accuracy: 0.9621 - val_loss: 0.2491\n",
            "Epoch 14/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9803 - loss: 0.1926 - val_accuracy: 0.9669 - val_loss: 0.2329\n",
            "Epoch 15/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9820 - loss: 0.1877 - val_accuracy: 0.9622 - val_loss: 0.2399\n",
            "Epoch 16/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9831 - loss: 0.1810 - val_accuracy: 0.9662 - val_loss: 0.2326\n",
            "Epoch 17/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9848 - loss: 0.1739 - val_accuracy: 0.9648 - val_loss: 0.2292\n",
            "Epoch 18/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9852 - loss: 0.1684 - val_accuracy: 0.9670 - val_loss: 0.2219\n",
            "Epoch 19/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9877 - loss: 0.1612 - val_accuracy: 0.9671 - val_loss: 0.2219\n",
            "Epoch 20/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9861 - loss: 0.1629 - val_accuracy: 0.9690 - val_loss: 0.2168\n",
            "Epoch 21/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9869 - loss: 0.1580 - val_accuracy: 0.9666 - val_loss: 0.2220\n",
            "Epoch 22/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9889 - loss: 0.1522 - val_accuracy: 0.9687 - val_loss: 0.2088\n",
            "Epoch 23/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9887 - loss: 0.1496 - val_accuracy: 0.9700 - val_loss: 0.2083\n",
            "Epoch 24/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9897 - loss: 0.1464 - val_accuracy: 0.9716 - val_loss: 0.2020\n",
            "Epoch 25/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9903 - loss: 0.1418 - val_accuracy: 0.9683 - val_loss: 0.2089\n",
            "Epoch 26/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9908 - loss: 0.1423 - val_accuracy: 0.9671 - val_loss: 0.2072\n",
            "Epoch 27/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9905 - loss: 0.1388 - val_accuracy: 0.9714 - val_loss: 0.2042\n",
            "Epoch 28/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9915 - loss: 0.1338 - val_accuracy: 0.9706 - val_loss: 0.2025\n",
            "Epoch 29/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9915 - loss: 0.1335 - val_accuracy: 0.9700 - val_loss: 0.2036\n",
            "Epoch 30/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9910 - loss: 0.1328 - val_accuracy: 0.9681 - val_loss: 0.2033\n",
            "Epoch 31/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9927 - loss: 0.1278 - val_accuracy: 0.9693 - val_loss: 0.2023\n",
            "Epoch 32/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9924 - loss: 0.1256 - val_accuracy: 0.9680 - val_loss: 0.2007\n",
            "Epoch 33/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9933 - loss: 0.1229 - val_accuracy: 0.9701 - val_loss: 0.1968\n",
            "Epoch 34/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9923 - loss: 0.1248 - val_accuracy: 0.9714 - val_loss: 0.1945\n",
            "Epoch 35/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9938 - loss: 0.1178 - val_accuracy: 0.9712 - val_loss: 0.1939\n",
            "Epoch 36/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9939 - loss: 0.1176 - val_accuracy: 0.9701 - val_loss: 0.1961\n",
            "Epoch 37/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9935 - loss: 0.1179 - val_accuracy: 0.9706 - val_loss: 0.1895\n",
            "Epoch 38/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9936 - loss: 0.1163 - val_accuracy: 0.9701 - val_loss: 0.1898\n",
            "Epoch 39/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9943 - loss: 0.1130 - val_accuracy: 0.9653 - val_loss: 0.2002\n",
            "Epoch 40/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9949 - loss: 0.1116 - val_accuracy: 0.9729 - val_loss: 0.1849\n",
            "Epoch 41/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9947 - loss: 0.1122 - val_accuracy: 0.9726 - val_loss: 0.1909\n",
            "Epoch 42/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 0.1109 - val_accuracy: 0.9724 - val_loss: 0.1876\n",
            "Epoch 43/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9946 - loss: 0.1091 - val_accuracy: 0.9749 - val_loss: 0.1857\n",
            "Epoch 44/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9950 - loss: 0.1064 - val_accuracy: 0.9692 - val_loss: 0.1915\n",
            "Epoch 45/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9955 - loss: 0.1075 - val_accuracy: 0.9719 - val_loss: 0.1892\n",
            "Epoch 46/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9954 - loss: 0.1044 - val_accuracy: 0.9714 - val_loss: 0.1821\n",
            "Epoch 47/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9958 - loss: 0.1031 - val_accuracy: 0.9710 - val_loss: 0.1823\n",
            "Epoch 48/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9956 - loss: 0.1036 - val_accuracy: 0.9706 - val_loss: 0.1813\n",
            "Epoch 49/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9953 - loss: 0.1025 - val_accuracy: 0.9739 - val_loss: 0.1783\n",
            "Epoch 50/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9970 - loss: 0.0987 - val_accuracy: 0.9691 - val_loss: 0.1914\n",
            "Training time for MLP 4-layer : 267.9540116786957 seconds\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9664 - loss: 0.2024\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mlp_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_2 (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │         \u001b[38;5;34m109,810\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">109,810</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,810\u001b[0m (428.95 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,810</span> (428.95 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,810\u001b[0m (428.95 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,810</span> (428.95 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Number of Layers'] = df['Number of Layers'].astype(np.int32)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "CL7XAmkQoINl",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26b34b47-6749-4512-f981-f308a87fa5ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Number of Layers      Loss  Accuracy        Time\n",
            "0                 2  0.145159  0.974667  222.539895\n",
            "1                 3  0.160991  0.974095  221.925477\n",
            "2                 4  0.194211  0.968095  267.954012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results:  Minimum difference with the loss and accuracy for all three different layers. 2-layer has the fastest time and 4-layer has the slowest time."
      ],
      "metadata": {
        "id": "CVsNT__u23us"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 2\n",
        "## Compare the performance of 2-layer MLP when using different settings\n",
        "\n",
        "### different weight initialization (RandomNormal, zeros, ones, GlorotNormal)\n",
        "### different regularization (l1, l2, l1_l2)\n",
        "### different optimizers (SDG , ADAM, Ftrl)\n",
        "\n",
        "### Default weight initialization: RandomNormal\n",
        "### Default regularization: l2\n",
        "### Default optimizer: SDG"
      ],
      "metadata": {
        "id": "JZ-uOODhlqe1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make a dataframe to compare the accuracy and loss for all the different activation\n",
        "df_task2 = pd.DataFrame(columns=['weight init','regularization',\n",
        "                           'optimizer', 'Loss', 'Accuracy','Time'])"
      ],
      "metadata": {
        "id": "_osGE1sftky5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Different Weight Initialization (RandomNormal, zeros, ones, GlorotNormal)"
      ],
      "metadata": {
        "id": "5yqpgH_hpefB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try : RandomNormal, zeros, ones, GlorotNormal\n",
        "\n",
        "intialweights = [{'name': 'RandomNormal','obj':tf.keras.initializers.RandomNormal()},\n",
        "                 {'name': 'zeros','obj':tf.keras.initializers.zeros()},\n",
        "                 {'name': 'ones','obj':tf.keras.initializers.ones()},\n",
        "                 {'name': 'GlorotNormal','obj':tf.keras.initializers.GlorotNormal()}]\n",
        "for idx, initweight in enumerate(intialweights):\n",
        "  mlp_idx = MLP(num_classes=10,\n",
        "            input_shape=(28*28,),\n",
        "            n_layers=2,\n",
        "            n_units=100,\n",
        "            activation='relu',\n",
        "            optim= tf.keras.optimizers.SGD(learning_rate=0.0002),\n",
        "            loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "            initializer=initweight['obj'],\n",
        "            reg = tf.keras.regularizers.l2(0.001))\n",
        "\n",
        "  mlp_idx.compile_model()\n",
        "\n",
        "  start = time.time()\n",
        "  mlp_idx.train_model(x_train, y_train, x_val, y_val, epochs=50, batch_size=32)\n",
        "  end = time.time()\n",
        "\n",
        "  print(f\"Training time for MLP_{idx} task 2 {initweight['name']} is the weight intialization: {end - start} seconds\")\n",
        "  print(\"\\n\")\n",
        "\n",
        "  test_loss, test_acc = mlp_idx.evaluate_model(x_test, y_test)\n",
        "\n",
        "  df_task2.loc[len(df_task2)] =[initweight['name'],'l2', 'SGD',test_loss, test_acc, end - start]\n",
        "\n",
        "  mlp_idx.summary()"
      ],
      "metadata": {
        "id": "re1pP1zywpnm",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1fb2989f-af35-4209-a249-b09789d0779d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.0753 - loss: 2.5274 - val_accuracy: 0.1037 - val_loss: 2.5120\n",
            "Epoch 2/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1086 - loss: 2.5082 - val_accuracy: 0.1438 - val_loss: 2.4939\n",
            "Epoch 3/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.1501 - loss: 2.4906 - val_accuracy: 0.1879 - val_loss: 2.4758\n",
            "Epoch 4/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1913 - loss: 2.4730 - val_accuracy: 0.2369 - val_loss: 2.4573\n",
            "Epoch 5/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.2411 - loss: 2.4548 - val_accuracy: 0.2867 - val_loss: 2.4381\n",
            "Epoch 6/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.2917 - loss: 2.4354 - val_accuracy: 0.3361 - val_loss: 2.4179\n",
            "Epoch 7/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3441 - loss: 2.4151 - val_accuracy: 0.3886 - val_loss: 2.3962\n",
            "Epoch 8/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3923 - loss: 2.3925 - val_accuracy: 0.4348 - val_loss: 2.3726\n",
            "Epoch 9/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4339 - loss: 2.3690 - val_accuracy: 0.4749 - val_loss: 2.3468\n",
            "Epoch 10/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4734 - loss: 2.3425 - val_accuracy: 0.5104 - val_loss: 2.3184\n",
            "Epoch 11/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5069 - loss: 2.3146 - val_accuracy: 0.5410 - val_loss: 2.2872\n",
            "Epoch 12/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5361 - loss: 2.2819 - val_accuracy: 0.5672 - val_loss: 2.2529\n",
            "Epoch 13/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5655 - loss: 2.2468 - val_accuracy: 0.5924 - val_loss: 2.2156\n",
            "Epoch 14/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5921 - loss: 2.2072 - val_accuracy: 0.6149 - val_loss: 2.1753\n",
            "Epoch 15/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6145 - loss: 2.1676 - val_accuracy: 0.6322 - val_loss: 2.1324\n",
            "Epoch 16/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6294 - loss: 2.1268 - val_accuracy: 0.6497 - val_loss: 2.0871\n",
            "Epoch 17/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6380 - loss: 2.0824 - val_accuracy: 0.6656 - val_loss: 2.0397\n",
            "Epoch 18/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6567 - loss: 2.0348 - val_accuracy: 0.6804 - val_loss: 1.9904\n",
            "Epoch 19/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6669 - loss: 1.9835 - val_accuracy: 0.6909 - val_loss: 1.9395\n",
            "Epoch 20/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6833 - loss: 1.9345 - val_accuracy: 0.7009 - val_loss: 1.8875\n",
            "Epoch 21/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7007 - loss: 1.8799 - val_accuracy: 0.7102 - val_loss: 1.8345\n",
            "Epoch 22/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7050 - loss: 1.8231 - val_accuracy: 0.7189 - val_loss: 1.7811\n",
            "Epoch 23/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7115 - loss: 1.7753 - val_accuracy: 0.7267 - val_loss: 1.7276\n",
            "Epoch 24/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7221 - loss: 1.7177 - val_accuracy: 0.7345 - val_loss: 1.6746\n",
            "Epoch 25/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7283 - loss: 1.6641 - val_accuracy: 0.7417 - val_loss: 1.6224\n",
            "Epoch 26/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7342 - loss: 1.6170 - val_accuracy: 0.7474 - val_loss: 1.5714\n",
            "Epoch 27/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7457 - loss: 1.5603 - val_accuracy: 0.7548 - val_loss: 1.5219\n",
            "Epoch 28/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7533 - loss: 1.5120 - val_accuracy: 0.7599 - val_loss: 1.4743\n",
            "Epoch 29/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7578 - loss: 1.4632 - val_accuracy: 0.7672 - val_loss: 1.4287\n",
            "Epoch 30/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7645 - loss: 1.4173 - val_accuracy: 0.7729 - val_loss: 1.3853\n",
            "Epoch 31/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7684 - loss: 1.3821 - val_accuracy: 0.7782 - val_loss: 1.3443\n",
            "Epoch 32/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7755 - loss: 1.3404 - val_accuracy: 0.7838 - val_loss: 1.3056\n",
            "Epoch 33/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7794 - loss: 1.3037 - val_accuracy: 0.7876 - val_loss: 1.2693\n",
            "Epoch 34/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7845 - loss: 1.2645 - val_accuracy: 0.7937 - val_loss: 1.2353\n",
            "Epoch 35/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7925 - loss: 1.2258 - val_accuracy: 0.7970 - val_loss: 1.2035\n",
            "Epoch 36/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7951 - loss: 1.1966 - val_accuracy: 0.8008 - val_loss: 1.1738\n",
            "Epoch 37/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7933 - loss: 1.1731 - val_accuracy: 0.8040 - val_loss: 1.1461\n",
            "Epoch 38/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7996 - loss: 1.1438 - val_accuracy: 0.8070 - val_loss: 1.1202\n",
            "Epoch 39/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8066 - loss: 1.1193 - val_accuracy: 0.8097 - val_loss: 1.0960\n",
            "Epoch 40/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8100 - loss: 1.0931 - val_accuracy: 0.8133 - val_loss: 1.0734\n",
            "Epoch 41/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8112 - loss: 1.0691 - val_accuracy: 0.8157 - val_loss: 1.0523\n",
            "Epoch 42/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8156 - loss: 1.0460 - val_accuracy: 0.8187 - val_loss: 1.0325\n",
            "Epoch 43/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8195 - loss: 1.0289 - val_accuracy: 0.8219 - val_loss: 1.0141\n",
            "Epoch 44/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8223 - loss: 1.0115 - val_accuracy: 0.8236 - val_loss: 0.9967\n",
            "Epoch 45/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8222 - loss: 1.0022 - val_accuracy: 0.8256 - val_loss: 0.9804\n",
            "Epoch 46/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8253 - loss: 0.9794 - val_accuracy: 0.8280 - val_loss: 0.9651\n",
            "Epoch 47/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8264 - loss: 0.9684 - val_accuracy: 0.8291 - val_loss: 0.9507\n",
            "Epoch 48/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8299 - loss: 0.9472 - val_accuracy: 0.8312 - val_loss: 0.9370\n",
            "Epoch 49/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8311 - loss: 0.9359 - val_accuracy: 0.8337 - val_loss: 0.9241\n",
            "Epoch 50/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8337 - loss: 0.9234 - val_accuracy: 0.8352 - val_loss: 0.9120\n",
            "Training time for MLP_0 task 2 RandomNormal is the weight intialization: 207.00257062911987 seconds\n",
            "\n",
            "\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8296 - loss: 0.9171\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mlp_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_3 (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │          \u001b[38;5;34m89,610\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.1098 - loss: 2.3026 - val_accuracy: 0.1106 - val_loss: 2.3026\n",
            "Epoch 2/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.1130 - loss: 2.3025 - val_accuracy: 0.1106 - val_loss: 2.3025\n",
            "Epoch 3/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1130 - loss: 2.3025 - val_accuracy: 0.1106 - val_loss: 2.3025\n",
            "Epoch 4/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1157 - loss: 2.3025 - val_accuracy: 0.1106 - val_loss: 2.3025\n",
            "Epoch 5/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1105 - loss: 2.3025 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 6/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1134 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 7/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1138 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 8/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1166 - loss: 2.3023 - val_accuracy: 0.1106 - val_loss: 2.3023\n",
            "Epoch 9/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1147 - loss: 2.3023 - val_accuracy: 0.1106 - val_loss: 2.3023\n",
            "Epoch 10/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1124 - loss: 2.3023 - val_accuracy: 0.1106 - val_loss: 2.3023\n",
            "Epoch 11/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1118 - loss: 2.3023 - val_accuracy: 0.1106 - val_loss: 2.3023\n",
            "Epoch 12/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1127 - loss: 2.3023 - val_accuracy: 0.1106 - val_loss: 2.3022\n",
            "Epoch 13/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1158 - loss: 2.3022 - val_accuracy: 0.1106 - val_loss: 2.3022\n",
            "Epoch 14/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1135 - loss: 2.3022 - val_accuracy: 0.1106 - val_loss: 2.3022\n",
            "Epoch 15/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1123 - loss: 2.3021 - val_accuracy: 0.1106 - val_loss: 2.3022\n",
            "Epoch 16/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1161 - loss: 2.3021 - val_accuracy: 0.1106 - val_loss: 2.3021\n",
            "Epoch 17/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.1125 - loss: 2.3022 - val_accuracy: 0.1106 - val_loss: 2.3021\n",
            "Epoch 18/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.1142 - loss: 2.3021 - val_accuracy: 0.1106 - val_loss: 2.3021\n",
            "Epoch 19/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.1112 - loss: 2.3021 - val_accuracy: 0.1106 - val_loss: 2.3021\n",
            "Epoch 20/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1144 - loss: 2.3021 - val_accuracy: 0.1106 - val_loss: 2.3021\n",
            "Epoch 21/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1118 - loss: 2.3021 - val_accuracy: 0.1106 - val_loss: 2.3020\n",
            "Epoch 22/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1147 - loss: 2.3019 - val_accuracy: 0.1106 - val_loss: 2.3020\n",
            "Epoch 23/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1144 - loss: 2.3020 - val_accuracy: 0.1106 - val_loss: 2.3020\n",
            "Epoch 24/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1112 - loss: 2.3020 - val_accuracy: 0.1106 - val_loss: 2.3020\n",
            "Epoch 25/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1143 - loss: 2.3020 - val_accuracy: 0.1106 - val_loss: 2.3020\n",
            "Epoch 26/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1135 - loss: 2.3020 - val_accuracy: 0.1106 - val_loss: 2.3019\n",
            "Epoch 27/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1120 - loss: 2.3020 - val_accuracy: 0.1106 - val_loss: 2.3019\n",
            "Epoch 28/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.3018 - val_accuracy: 0.1106 - val_loss: 2.3019\n",
            "Epoch 29/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1100 - loss: 2.3020 - val_accuracy: 0.1106 - val_loss: 2.3019\n",
            "Epoch 30/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1151 - loss: 2.3017 - val_accuracy: 0.1106 - val_loss: 2.3019\n",
            "Epoch 31/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1129 - loss: 2.3019 - val_accuracy: 0.1106 - val_loss: 2.3019\n",
            "Epoch 32/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1114 - loss: 2.3019 - val_accuracy: 0.1106 - val_loss: 2.3018\n",
            "Epoch 33/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1151 - loss: 2.3017 - val_accuracy: 0.1106 - val_loss: 2.3018\n",
            "Epoch 34/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1119 - loss: 2.3018 - val_accuracy: 0.1106 - val_loss: 2.3018\n",
            "Epoch 35/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1149 - loss: 2.3016 - val_accuracy: 0.1106 - val_loss: 2.3018\n",
            "Epoch 36/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.1146 - loss: 2.3018 - val_accuracy: 0.1106 - val_loss: 2.3018\n",
            "Epoch 37/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1111 - loss: 2.3018 - val_accuracy: 0.1106 - val_loss: 2.3018\n",
            "Epoch 38/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1134 - loss: 2.3018 - val_accuracy: 0.1106 - val_loss: 2.3018\n",
            "Epoch 39/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1139 - loss: 2.3017 - val_accuracy: 0.1106 - val_loss: 2.3017\n",
            "Epoch 40/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.1169 - loss: 2.3015 - val_accuracy: 0.1106 - val_loss: 2.3017\n",
            "Epoch 41/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1139 - loss: 2.3016 - val_accuracy: 0.1106 - val_loss: 2.3017\n",
            "Epoch 42/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1129 - loss: 2.3017 - val_accuracy: 0.1106 - val_loss: 2.3017\n",
            "Epoch 43/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1126 - loss: 2.3018 - val_accuracy: 0.1106 - val_loss: 2.3017\n",
            "Epoch 44/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1115 - loss: 2.3018 - val_accuracy: 0.1106 - val_loss: 2.3017\n",
            "Epoch 45/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1128 - loss: 2.3017 - val_accuracy: 0.1106 - val_loss: 2.3017\n",
            "Epoch 46/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.1142 - loss: 2.3016 - val_accuracy: 0.1106 - val_loss: 2.3017\n",
            "Epoch 47/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.1098 - loss: 2.3019 - val_accuracy: 0.1106 - val_loss: 2.3017\n",
            "Epoch 48/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1140 - loss: 2.3015 - val_accuracy: 0.1106 - val_loss: 2.3016\n",
            "Epoch 49/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1136 - loss: 2.3017 - val_accuracy: 0.1106 - val_loss: 2.3016\n",
            "Epoch 50/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.1100 - loss: 2.3018 - val_accuracy: 0.1106 - val_loss: 2.3016\n",
            "Training time for MLP_1 task 2 zeros is the weight intialization: 210.11819458007812 seconds\n",
            "\n",
            "\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1121 - loss: 2.3017\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mlp_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_4 (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │          \u001b[38;5;34m89,610\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.0985 - loss: 143832.5156 - val_accuracy: 0.1001 - val_loss: 70.9219\n",
            "Epoch 2/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1011 - loss: 70.8767 - val_accuracy: 0.1003 - val_loss: 70.7490\n",
            "Epoch 3/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.0990 - loss: 70.5939 - val_accuracy: 0.1001 - val_loss: 70.5533\n",
            "Epoch 4/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.0987 - loss: 70.5219 - val_accuracy: 0.0990 - val_loss: 70.4816\n",
            "Epoch 5/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.0991 - loss: 70.4642 - val_accuracy: 0.1031 - val_loss: 70.4063\n",
            "Epoch 6/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.1001 - loss: 70.3981 - val_accuracy: 0.1031 - val_loss: 70.3647\n",
            "Epoch 7/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.0987 - loss: 70.3612 - val_accuracy: 0.1031 - val_loss: 70.3306\n",
            "Epoch 8/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1002 - loss: 70.3262 - val_accuracy: 0.1031 - val_loss: 70.2970\n",
            "Epoch 9/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.0980 - loss: 70.2922 - val_accuracy: 0.1031 - val_loss: 70.2605\n",
            "Epoch 10/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.0972 - loss: 70.2570 - val_accuracy: 0.1031 - val_loss: 70.2255\n",
            "Epoch 11/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.0983 - loss: 70.2216 - val_accuracy: 0.1031 - val_loss: 70.1914\n",
            "Epoch 12/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.0979 - loss: 70.1885 - val_accuracy: 0.1031 - val_loss: 70.1603\n",
            "Epoch 13/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.1001 - loss: 70.1524 - val_accuracy: 0.1032 - val_loss: 70.1244\n",
            "Epoch 14/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.0980 - loss: 70.1183 - val_accuracy: 0.1031 - val_loss: 70.0882\n",
            "Epoch 15/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.0993 - loss: 70.0830 - val_accuracy: 0.1031 - val_loss: 70.0539\n",
            "Epoch 16/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0981 - loss: 70.0495 - val_accuracy: 0.1031 - val_loss: 70.0206\n",
            "Epoch 17/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.0981 - loss: 70.0145 - val_accuracy: 0.1031 - val_loss: 69.9835\n",
            "Epoch 18/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.0994 - loss: 69.9796 - val_accuracy: 0.1032 - val_loss: 69.9494\n",
            "Epoch 19/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.0974 - loss: 69.9458 - val_accuracy: 0.1031 - val_loss: 69.9153\n",
            "Epoch 20/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.0978 - loss: 69.9109 - val_accuracy: 0.1033 - val_loss: 69.8864\n",
            "Epoch 21/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.0996 - loss: 69.8754 - val_accuracy: 0.1064 - val_loss: 69.8534\n",
            "Epoch 22/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.0984 - loss: 69.8418 - val_accuracy: 0.1039 - val_loss: 69.8123\n",
            "Epoch 23/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.0985 - loss: 69.8074 - val_accuracy: 0.1033 - val_loss: 69.7797\n",
            "Epoch 24/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.0984 - loss: 69.7729 - val_accuracy: 0.1036 - val_loss: 69.7429\n",
            "Epoch 25/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1013 - loss: 69.7362 - val_accuracy: 0.1066 - val_loss: 69.7118\n",
            "Epoch 26/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1010 - loss: 69.7040 - val_accuracy: 0.1036 - val_loss: 69.6736\n",
            "Epoch 27/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1014 - loss: 69.6685 - val_accuracy: 0.1033 - val_loss: 69.6391\n",
            "Epoch 28/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.0988 - loss: 69.6352 - val_accuracy: 0.1040 - val_loss: 69.6050\n",
            "Epoch 29/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.0995 - loss: 69.6009 - val_accuracy: 0.1040 - val_loss: 69.5717\n",
            "Epoch 30/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.1005 - loss: 69.5681 - val_accuracy: 0.1049 - val_loss: 69.5366\n",
            "Epoch 31/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.0991 - loss: 69.5333 - val_accuracy: 0.1037 - val_loss: 69.5020\n",
            "Epoch 32/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.0977 - loss: 69.4990 - val_accuracy: 0.1036 - val_loss: 69.4714\n",
            "Epoch 33/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.0991 - loss: 69.4643 - val_accuracy: 0.1046 - val_loss: 69.4351\n",
            "Epoch 34/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1020 - loss: 69.4298 - val_accuracy: 0.1035 - val_loss: 69.4002\n",
            "Epoch 35/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1038 - loss: 69.3952 - val_accuracy: 0.1043 - val_loss: 69.3650\n",
            "Epoch 36/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1036 - loss: 69.3607 - val_accuracy: 0.1036 - val_loss: 69.3336\n",
            "Epoch 37/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1014 - loss: 69.3268 - val_accuracy: 0.1067 - val_loss: 69.2983\n",
            "Epoch 38/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1032 - loss: 69.2925 - val_accuracy: 0.1045 - val_loss: 69.2630\n",
            "Epoch 39/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1048 - loss: 69.2583 - val_accuracy: 0.1070 - val_loss: 69.2303\n",
            "Epoch 40/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1049 - loss: 69.2247 - val_accuracy: 0.1080 - val_loss: 69.1964\n",
            "Epoch 41/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1075 - loss: 69.1900 - val_accuracy: 0.1104 - val_loss: 69.1602\n",
            "Epoch 42/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1064 - loss: 69.1562 - val_accuracy: 0.1056 - val_loss: 69.1265\n",
            "Epoch 43/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1092 - loss: 69.1215 - val_accuracy: 0.1048 - val_loss: 69.0933\n",
            "Epoch 44/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1079 - loss: 69.0897 - val_accuracy: 0.1176 - val_loss: 69.0590\n",
            "Epoch 45/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1112 - loss: 69.0543 - val_accuracy: 0.1067 - val_loss: 69.0250\n",
            "Epoch 46/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1087 - loss: 69.0201 - val_accuracy: 0.1126 - val_loss: 68.9902\n",
            "Epoch 47/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1133 - loss: 68.9849 - val_accuracy: 0.1065 - val_loss: 68.9570\n",
            "Epoch 48/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1116 - loss: 68.9492 - val_accuracy: 0.1156 - val_loss: 68.9230\n",
            "Epoch 49/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1152 - loss: 68.9163 - val_accuracy: 0.1148 - val_loss: 68.8883\n",
            "Epoch 50/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1179 - loss: 68.8836 - val_accuracy: 0.1361 - val_loss: 68.8566\n",
            "Training time for MLP_2 task 2 ones is the weight intialization: 197.12167096138 seconds\n",
            "\n",
            "\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1324 - loss: 68.8598\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mlp_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_5 (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │          \u001b[38;5;34m89,610\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.1149 - loss: 2.5698 - val_accuracy: 0.1449 - val_loss: 2.5286\n",
            "Epoch 2/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1515 - loss: 2.5166 - val_accuracy: 0.1973 - val_loss: 2.4777\n",
            "Epoch 3/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2089 - loss: 2.4678 - val_accuracy: 0.2655 - val_loss: 2.4268\n",
            "Epoch 4/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.2821 - loss: 2.4177 - val_accuracy: 0.3437 - val_loss: 2.3745\n",
            "Epoch 5/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3607 - loss: 2.3629 - val_accuracy: 0.4255 - val_loss: 2.3200\n",
            "Epoch 6/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4455 - loss: 2.3089 - val_accuracy: 0.4961 - val_loss: 2.2625\n",
            "Epoch 7/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5078 - loss: 2.2506 - val_accuracy: 0.5484 - val_loss: 2.2019\n",
            "Epoch 8/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5588 - loss: 2.1868 - val_accuracy: 0.5895 - val_loss: 2.1382\n",
            "Epoch 9/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5944 - loss: 2.1278 - val_accuracy: 0.6201 - val_loss: 2.0717\n",
            "Epoch 10/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6289 - loss: 2.0581 - val_accuracy: 0.6504 - val_loss: 2.0032\n",
            "Epoch 11/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6516 - loss: 1.9891 - val_accuracy: 0.6742 - val_loss: 1.9332\n",
            "Epoch 12/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6754 - loss: 1.9205 - val_accuracy: 0.6901 - val_loss: 1.8629\n",
            "Epoch 13/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6933 - loss: 1.8494 - val_accuracy: 0.7044 - val_loss: 1.7930\n",
            "Epoch 14/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7070 - loss: 1.7793 - val_accuracy: 0.7209 - val_loss: 1.7244\n",
            "Epoch 15/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7199 - loss: 1.7116 - val_accuracy: 0.7324 - val_loss: 1.6579\n",
            "Epoch 16/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7309 - loss: 1.6440 - val_accuracy: 0.7433 - val_loss: 1.5943\n",
            "Epoch 17/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7399 - loss: 1.5851 - val_accuracy: 0.7537 - val_loss: 1.5339\n",
            "Epoch 18/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7505 - loss: 1.5251 - val_accuracy: 0.7611 - val_loss: 1.4772\n",
            "Epoch 19/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7609 - loss: 1.4682 - val_accuracy: 0.7690 - val_loss: 1.4242\n",
            "Epoch 20/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7664 - loss: 1.4158 - val_accuracy: 0.7754 - val_loss: 1.3751\n",
            "Epoch 21/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7706 - loss: 1.3724 - val_accuracy: 0.7808 - val_loss: 1.3298\n",
            "Epoch 22/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7852 - loss: 1.3197 - val_accuracy: 0.7862 - val_loss: 1.2881\n",
            "Epoch 23/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7911 - loss: 1.2790 - val_accuracy: 0.7929 - val_loss: 1.2497\n",
            "Epoch 24/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7948 - loss: 1.2469 - val_accuracy: 0.7994 - val_loss: 1.2143\n",
            "Epoch 25/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8029 - loss: 1.2032 - val_accuracy: 0.8053 - val_loss: 1.1819\n",
            "Epoch 26/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8027 - loss: 1.1817 - val_accuracy: 0.8101 - val_loss: 1.1521\n",
            "Epoch 27/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8074 - loss: 1.1508 - val_accuracy: 0.8163 - val_loss: 1.1247\n",
            "Epoch 28/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8114 - loss: 1.1228 - val_accuracy: 0.8200 - val_loss: 1.0993\n",
            "Epoch 29/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8156 - loss: 1.0954 - val_accuracy: 0.8236 - val_loss: 1.0759\n",
            "Epoch 30/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8192 - loss: 1.0765 - val_accuracy: 0.8268 - val_loss: 1.0542\n",
            "Epoch 31/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8216 - loss: 1.0533 - val_accuracy: 0.8290 - val_loss: 1.0341\n",
            "Epoch 32/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8221 - loss: 1.0366 - val_accuracy: 0.8312 - val_loss: 1.0155\n",
            "Epoch 33/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8262 - loss: 1.0145 - val_accuracy: 0.8335 - val_loss: 0.9980\n",
            "Epoch 34/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8341 - loss: 0.9914 - val_accuracy: 0.8356 - val_loss: 0.9818\n",
            "Epoch 35/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8349 - loss: 0.9818 - val_accuracy: 0.8371 - val_loss: 0.9666\n",
            "Epoch 36/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8358 - loss: 0.9658 - val_accuracy: 0.8395 - val_loss: 0.9525\n",
            "Epoch 37/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8360 - loss: 0.9549 - val_accuracy: 0.8411 - val_loss: 0.9391\n",
            "Epoch 38/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8392 - loss: 0.9405 - val_accuracy: 0.8422 - val_loss: 0.9266\n",
            "Epoch 39/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8440 - loss: 0.9260 - val_accuracy: 0.8443 - val_loss: 0.9149\n",
            "Epoch 40/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8454 - loss: 0.9126 - val_accuracy: 0.8467 - val_loss: 0.9038\n",
            "Epoch 41/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8476 - loss: 0.9026 - val_accuracy: 0.8485 - val_loss: 0.8933\n",
            "Epoch 42/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8462 - loss: 0.8941 - val_accuracy: 0.8508 - val_loss: 0.8834\n",
            "Epoch 43/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8525 - loss: 0.8833 - val_accuracy: 0.8519 - val_loss: 0.8740\n",
            "Epoch 44/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8507 - loss: 0.8780 - val_accuracy: 0.8533 - val_loss: 0.8652\n",
            "Epoch 45/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8514 - loss: 0.8717 - val_accuracy: 0.8551 - val_loss: 0.8567\n",
            "Epoch 46/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8513 - loss: 0.8662 - val_accuracy: 0.8562 - val_loss: 0.8488\n",
            "Epoch 47/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8546 - loss: 0.8481 - val_accuracy: 0.8567 - val_loss: 0.8411\n",
            "Epoch 48/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8573 - loss: 0.8421 - val_accuracy: 0.8582 - val_loss: 0.8340\n",
            "Epoch 49/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8573 - loss: 0.8363 - val_accuracy: 0.8587 - val_loss: 0.8270\n",
            "Epoch 50/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8569 - loss: 0.8324 - val_accuracy: 0.8600 - val_loss: 0.8203\n",
            "Training time for MLP_3 task 2 GlorotNormal is the weight intialization: 209.67060565948486 seconds\n",
            "\n",
            "\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8586 - loss: 0.8234\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mlp_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_6 (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │          \u001b[38;5;34m89,610\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Different regularizations (l1, l2, l1_l2)"
      ],
      "metadata": {
        "id": "CukRJVknppma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try : l1, l2, l1_l2\n",
        "reguleriers = [{'name': 'l1', 'obj': tf.keras.regularizers.l1(0.001)},\n",
        "               {'name': 'l2', 'obj': tf.keras.regularizers.l2(0.001)},\n",
        "               {'name': 'l1_l2', 'obj': tf.keras.regularizers.l1_l2(0.001)}]\n",
        "for idx, reg in enumerate(reguleriers):\n",
        "  mlp_idx = MLP(num_classes=10,\n",
        "            input_shape=(28*28,),\n",
        "            n_layers=2,\n",
        "            n_units=100,\n",
        "            activation='relu',\n",
        "            optim= tf.keras.optimizers.SGD(learning_rate=0.0002),\n",
        "            loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "            initializer=tf.keras.initializers.RandomNormal(),\n",
        "            reg = reg['obj'])\n",
        "\n",
        "  mlp_idx.compile_model()\n",
        "\n",
        "  start = time.time()\n",
        "  mlp_idx.train_model(x_train, y_train, x_val, y_val, epochs=50, batch_size=32)\n",
        "  end = time.time()\n",
        "\n",
        "  print(f\"Training time for MLP task 2 {reg['name']} regularization: {end - start} seconds\")\n",
        "  print(\"\\n\")\n",
        "\n",
        "  test_loss, test_acc = mlp_idx.evaluate_model(x_test, y_test)\n",
        "\n",
        "  df_task2.loc[len(df_task2)] =['RandomNormal',reg['name'], 'SGD',test_loss, test_acc, end - start]\n",
        "\n",
        "  mlp_idx.summary()"
      ],
      "metadata": {
        "id": "Ojk9trllpo--",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8e003580-b996-4dd9-8a08-0e0ef98fe0ea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.1211 - loss: 5.7893 - val_accuracy: 0.1557 - val_loss: 5.7675\n",
            "Epoch 2/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.1647 - loss: 5.7595 - val_accuracy: 0.2043 - val_loss: 5.7385\n",
            "Epoch 3/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2127 - loss: 5.7306 - val_accuracy: 0.2474 - val_loss: 5.7093\n",
            "Epoch 4/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2556 - loss: 5.7016 - val_accuracy: 0.2880 - val_loss: 5.6796\n",
            "Epoch 5/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2946 - loss: 5.6724 - val_accuracy: 0.3239 - val_loss: 5.6492\n",
            "Epoch 6/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3321 - loss: 5.6407 - val_accuracy: 0.3536 - val_loss: 5.6177\n",
            "Epoch 7/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3609 - loss: 5.6095 - val_accuracy: 0.3883 - val_loss: 5.5850\n",
            "Epoch 8/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3913 - loss: 5.5777 - val_accuracy: 0.4213 - val_loss: 5.5507\n",
            "Epoch 9/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4274 - loss: 5.5415 - val_accuracy: 0.4516 - val_loss: 5.5147\n",
            "Epoch 10/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4610 - loss: 5.5051 - val_accuracy: 0.4796 - val_loss: 5.4766\n",
            "Epoch 11/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4827 - loss: 5.4673 - val_accuracy: 0.5039 - val_loss: 5.4365\n",
            "Epoch 12/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5050 - loss: 5.4274 - val_accuracy: 0.5272 - val_loss: 5.3942\n",
            "Epoch 13/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5295 - loss: 5.3845 - val_accuracy: 0.5452 - val_loss: 5.3498\n",
            "Epoch 14/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5481 - loss: 5.3392 - val_accuracy: 0.5618 - val_loss: 5.3032\n",
            "Epoch 15/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5632 - loss: 5.2933 - val_accuracy: 0.5793 - val_loss: 5.2546\n",
            "Epoch 16/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5768 - loss: 5.2456 - val_accuracy: 0.5945 - val_loss: 5.2039\n",
            "Epoch 17/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5948 - loss: 5.1925 - val_accuracy: 0.6117 - val_loss: 5.1514\n",
            "Epoch 18/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6115 - loss: 5.1408 - val_accuracy: 0.6291 - val_loss: 5.0973\n",
            "Epoch 19/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6275 - loss: 5.0851 - val_accuracy: 0.6434 - val_loss: 5.0417\n",
            "Epoch 20/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6420 - loss: 5.0282 - val_accuracy: 0.6559 - val_loss: 4.9849\n",
            "Epoch 21/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6546 - loss: 4.9737 - val_accuracy: 0.6678 - val_loss: 4.9273\n",
            "Epoch 22/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6699 - loss: 4.9165 - val_accuracy: 0.6791 - val_loss: 4.8694\n",
            "Epoch 23/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6822 - loss: 4.8566 - val_accuracy: 0.6895 - val_loss: 4.8115\n",
            "Epoch 24/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6928 - loss: 4.7987 - val_accuracy: 0.7011 - val_loss: 4.7542\n",
            "Epoch 25/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7001 - loss: 4.7441 - val_accuracy: 0.7112 - val_loss: 4.6978\n",
            "Epoch 26/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7127 - loss: 4.6898 - val_accuracy: 0.7199 - val_loss: 4.6428\n",
            "Epoch 27/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7273 - loss: 4.6329 - val_accuracy: 0.7293 - val_loss: 4.5895\n",
            "Epoch 28/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7305 - loss: 4.5814 - val_accuracy: 0.7378 - val_loss: 4.5382\n",
            "Epoch 29/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7412 - loss: 4.5280 - val_accuracy: 0.7448 - val_loss: 4.4889\n",
            "Epoch 30/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7470 - loss: 4.4793 - val_accuracy: 0.7508 - val_loss: 4.4416\n",
            "Epoch 31/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.7546 - loss: 4.4315 - val_accuracy: 0.7563 - val_loss: 4.3964\n",
            "Epoch 32/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7557 - loss: 4.3915 - val_accuracy: 0.7622 - val_loss: 4.3531\n",
            "Epoch 33/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7663 - loss: 4.3431 - val_accuracy: 0.7670 - val_loss: 4.3117\n",
            "Epoch 34/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7703 - loss: 4.3039 - val_accuracy: 0.7719 - val_loss: 4.2722\n",
            "Epoch 35/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7767 - loss: 4.2631 - val_accuracy: 0.7773 - val_loss: 4.2345\n",
            "Epoch 36/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7765 - loss: 4.2261 - val_accuracy: 0.7814 - val_loss: 4.1985\n",
            "Epoch 37/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7838 - loss: 4.1898 - val_accuracy: 0.7840 - val_loss: 4.1642\n",
            "Epoch 38/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7882 - loss: 4.1597 - val_accuracy: 0.7859 - val_loss: 4.1316\n",
            "Epoch 39/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7884 - loss: 4.1265 - val_accuracy: 0.7909 - val_loss: 4.1003\n",
            "Epoch 40/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7939 - loss: 4.0955 - val_accuracy: 0.7938 - val_loss: 4.0705\n",
            "Epoch 41/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7968 - loss: 4.0625 - val_accuracy: 0.7954 - val_loss: 4.0419\n",
            "Epoch 42/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7993 - loss: 4.0389 - val_accuracy: 0.7974 - val_loss: 4.0146\n",
            "Epoch 43/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7999 - loss: 4.0056 - val_accuracy: 0.7995 - val_loss: 3.9884\n",
            "Epoch 44/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8028 - loss: 3.9876 - val_accuracy: 0.8021 - val_loss: 3.9632\n",
            "Epoch 45/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8055 - loss: 3.9607 - val_accuracy: 0.8037 - val_loss: 3.9390\n",
            "Epoch 46/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8057 - loss: 3.9387 - val_accuracy: 0.8056 - val_loss: 3.9156\n",
            "Epoch 47/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8071 - loss: 3.9144 - val_accuracy: 0.8073 - val_loss: 3.8931\n",
            "Epoch 48/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8149 - loss: 3.8840 - val_accuracy: 0.8106 - val_loss: 3.8714\n",
            "Epoch 49/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8118 - loss: 3.8687 - val_accuracy: 0.8121 - val_loss: 3.8503\n",
            "Epoch 50/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8144 - loss: 3.8505 - val_accuracy: 0.8143 - val_loss: 3.8299\n",
            "Training time for MLP task 2 l1 regularization: 200.4430923461914 seconds\n",
            "\n",
            "\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8134 - loss: 3.8316\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mlp_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_7 (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │          \u001b[38;5;34m89,610\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.0961 - loss: 2.5239 - val_accuracy: 0.1002 - val_loss: 2.5088\n",
            "Epoch 2/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1028 - loss: 2.5042 - val_accuracy: 0.1086 - val_loss: 2.4890\n",
            "Epoch 3/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.1183 - loss: 2.4823 - val_accuracy: 0.1291 - val_loss: 2.4694\n",
            "Epoch 4/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1352 - loss: 2.4653 - val_accuracy: 0.1630 - val_loss: 2.4496\n",
            "Epoch 5/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.1689 - loss: 2.4456 - val_accuracy: 0.2077 - val_loss: 2.4291\n",
            "Epoch 6/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2129 - loss: 2.4248 - val_accuracy: 0.2497 - val_loss: 2.4077\n",
            "Epoch 7/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2597 - loss: 2.4025 - val_accuracy: 0.2978 - val_loss: 2.3850\n",
            "Epoch 8/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3079 - loss: 2.3813 - val_accuracy: 0.3471 - val_loss: 2.3606\n",
            "Epoch 9/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3511 - loss: 2.3572 - val_accuracy: 0.3915 - val_loss: 2.3344\n",
            "Epoch 10/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3948 - loss: 2.3280 - val_accuracy: 0.4331 - val_loss: 2.3059\n",
            "Epoch 11/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4388 - loss: 2.2985 - val_accuracy: 0.4693 - val_loss: 2.2751\n",
            "Epoch 12/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4672 - loss: 2.2687 - val_accuracy: 0.4986 - val_loss: 2.2418\n",
            "Epoch 13/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4991 - loss: 2.2355 - val_accuracy: 0.5242 - val_loss: 2.2059\n",
            "Epoch 14/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5320 - loss: 2.1957 - val_accuracy: 0.5454 - val_loss: 2.1675\n",
            "Epoch 15/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5528 - loss: 2.1598 - val_accuracy: 0.5697 - val_loss: 2.1268\n",
            "Epoch 16/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5758 - loss: 2.1173 - val_accuracy: 0.5916 - val_loss: 2.0840\n",
            "Epoch 17/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5983 - loss: 2.0725 - val_accuracy: 0.6138 - val_loss: 2.0389\n",
            "Epoch 18/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6220 - loss: 2.0276 - val_accuracy: 0.6304 - val_loss: 1.9918\n",
            "Epoch 19/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6361 - loss: 1.9812 - val_accuracy: 0.6529 - val_loss: 1.9428\n",
            "Epoch 20/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6612 - loss: 1.9270 - val_accuracy: 0.6699 - val_loss: 1.8923\n",
            "Epoch 21/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6739 - loss: 1.8813 - val_accuracy: 0.6861 - val_loss: 1.8405\n",
            "Epoch 22/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6900 - loss: 1.8285 - val_accuracy: 0.7000 - val_loss: 1.7879\n",
            "Epoch 23/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7016 - loss: 1.7780 - val_accuracy: 0.7135 - val_loss: 1.7349\n",
            "Epoch 24/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7157 - loss: 1.7204 - val_accuracy: 0.7240 - val_loss: 1.6819\n",
            "Epoch 25/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7283 - loss: 1.6707 - val_accuracy: 0.7320 - val_loss: 1.6295\n",
            "Epoch 26/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7406 - loss: 1.6160 - val_accuracy: 0.7412 - val_loss: 1.5780\n",
            "Epoch 27/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7499 - loss: 1.5632 - val_accuracy: 0.7504 - val_loss: 1.5281\n",
            "Epoch 28/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7594 - loss: 1.5185 - val_accuracy: 0.7574 - val_loss: 1.4800\n",
            "Epoch 29/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7598 - loss: 1.4703 - val_accuracy: 0.7635 - val_loss: 1.4339\n",
            "Epoch 30/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7653 - loss: 1.4296 - val_accuracy: 0.7694 - val_loss: 1.3901\n",
            "Epoch 31/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7773 - loss: 1.3762 - val_accuracy: 0.7743 - val_loss: 1.3486\n",
            "Epoch 32/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7818 - loss: 1.3364 - val_accuracy: 0.7778 - val_loss: 1.3095\n",
            "Epoch 33/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7839 - loss: 1.2980 - val_accuracy: 0.7816 - val_loss: 1.2728\n",
            "Epoch 34/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7829 - loss: 1.2672 - val_accuracy: 0.7854 - val_loss: 1.2385\n",
            "Epoch 35/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7882 - loss: 1.2350 - val_accuracy: 0.7883 - val_loss: 1.2065\n",
            "Epoch 36/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7956 - loss: 1.1965 - val_accuracy: 0.7922 - val_loss: 1.1766\n",
            "Epoch 37/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7939 - loss: 1.1720 - val_accuracy: 0.7939 - val_loss: 1.1487\n",
            "Epoch 38/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7988 - loss: 1.1410 - val_accuracy: 0.7973 - val_loss: 1.1228\n",
            "Epoch 39/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8033 - loss: 1.1110 - val_accuracy: 0.8006 - val_loss: 1.0984\n",
            "Epoch 40/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8073 - loss: 1.0900 - val_accuracy: 0.8037 - val_loss: 1.0759\n",
            "Epoch 41/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8056 - loss: 1.0674 - val_accuracy: 0.8053 - val_loss: 1.0548\n",
            "Epoch 42/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8093 - loss: 1.0479 - val_accuracy: 0.8076 - val_loss: 1.0350\n",
            "Epoch 43/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8151 - loss: 1.0262 - val_accuracy: 0.8088 - val_loss: 1.0165\n",
            "Epoch 44/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8116 - loss: 1.0133 - val_accuracy: 0.8124 - val_loss: 0.9991\n",
            "Epoch 45/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8150 - loss: 0.9980 - val_accuracy: 0.8144 - val_loss: 0.9828\n",
            "Epoch 46/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8187 - loss: 0.9784 - val_accuracy: 0.8166 - val_loss: 0.9676\n",
            "Epoch 47/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8212 - loss: 0.9659 - val_accuracy: 0.8191 - val_loss: 0.9532\n",
            "Epoch 48/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8266 - loss: 0.9478 - val_accuracy: 0.8213 - val_loss: 0.9396\n",
            "Epoch 49/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8270 - loss: 0.9316 - val_accuracy: 0.8238 - val_loss: 0.9268\n",
            "Epoch 50/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8272 - loss: 0.9202 - val_accuracy: 0.8251 - val_loss: 0.9147\n",
            "Training time for MLP task 2 l2 regularization: 219.04692769050598 seconds\n",
            "\n",
            "\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8257 - loss: 0.9189\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mlp_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_8 (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │          \u001b[38;5;34m89,610\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1314 - loss: 5.8405 - val_accuracy: 0.1570 - val_loss: 5.8116\n",
            "Epoch 2/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.1596 - loss: 5.8051 - val_accuracy: 0.1866 - val_loss: 5.7767\n",
            "Epoch 3/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1915 - loss: 5.7702 - val_accuracy: 0.2149 - val_loss: 5.7423\n",
            "Epoch 4/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.2183 - loss: 5.7372 - val_accuracy: 0.2526 - val_loss: 5.7078\n",
            "Epoch 5/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2590 - loss: 5.7024 - val_accuracy: 0.2999 - val_loss: 5.6726\n",
            "Epoch 6/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3060 - loss: 5.6660 - val_accuracy: 0.3533 - val_loss: 5.6362\n",
            "Epoch 7/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3584 - loss: 5.6288 - val_accuracy: 0.3944 - val_loss: 5.5983\n",
            "Epoch 8/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3968 - loss: 5.5917 - val_accuracy: 0.4360 - val_loss: 5.5587\n",
            "Epoch 9/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4384 - loss: 5.5510 - val_accuracy: 0.4733 - val_loss: 5.5172\n",
            "Epoch 10/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4744 - loss: 5.5097 - val_accuracy: 0.5038 - val_loss: 5.4736\n",
            "Epoch 11/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5024 - loss: 5.4674 - val_accuracy: 0.5352 - val_loss: 5.4281\n",
            "Epoch 12/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5350 - loss: 5.4200 - val_accuracy: 0.5621 - val_loss: 5.3806\n",
            "Epoch 13/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5682 - loss: 5.3703 - val_accuracy: 0.5820 - val_loss: 5.3312\n",
            "Epoch 14/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5855 - loss: 5.3219 - val_accuracy: 0.6013 - val_loss: 5.2801\n",
            "Epoch 15/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6046 - loss: 5.2711 - val_accuracy: 0.6174 - val_loss: 5.2274\n",
            "Epoch 16/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6206 - loss: 5.2208 - val_accuracy: 0.6308 - val_loss: 5.1734\n",
            "Epoch 17/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6391 - loss: 5.1623 - val_accuracy: 0.6458 - val_loss: 5.1181\n",
            "Epoch 18/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6490 - loss: 5.1081 - val_accuracy: 0.6585 - val_loss: 5.0618\n",
            "Epoch 19/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6654 - loss: 5.0487 - val_accuracy: 0.6691 - val_loss: 5.0049\n",
            "Epoch 20/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6721 - loss: 4.9957 - val_accuracy: 0.6806 - val_loss: 4.9474\n",
            "Epoch 21/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6818 - loss: 4.9395 - val_accuracy: 0.6907 - val_loss: 4.8897\n",
            "Epoch 22/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7000 - loss: 4.8724 - val_accuracy: 0.7014 - val_loss: 4.8324\n",
            "Epoch 23/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7035 - loss: 4.8245 - val_accuracy: 0.7091 - val_loss: 4.7754\n",
            "Epoch 24/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.7162 - loss: 4.7646 - val_accuracy: 0.7171 - val_loss: 4.7193\n",
            "Epoch 25/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7216 - loss: 4.7097 - val_accuracy: 0.7264 - val_loss: 4.6644\n",
            "Epoch 26/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7325 - loss: 4.6522 - val_accuracy: 0.7349 - val_loss: 4.6107\n",
            "Epoch 27/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7399 - loss: 4.5990 - val_accuracy: 0.7423 - val_loss: 4.5587\n",
            "Epoch 28/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7461 - loss: 4.5469 - val_accuracy: 0.7511 - val_loss: 4.5085\n",
            "Epoch 29/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7489 - loss: 4.5037 - val_accuracy: 0.7550 - val_loss: 4.4603\n",
            "Epoch 30/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7574 - loss: 4.4507 - val_accuracy: 0.7609 - val_loss: 4.4140\n",
            "Epoch 31/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7653 - loss: 4.4020 - val_accuracy: 0.7661 - val_loss: 4.3698\n",
            "Epoch 32/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7718 - loss: 4.3631 - val_accuracy: 0.7708 - val_loss: 4.3276\n",
            "Epoch 33/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7723 - loss: 4.3211 - val_accuracy: 0.7748 - val_loss: 4.2874\n",
            "Epoch 34/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7773 - loss: 4.2843 - val_accuracy: 0.7779 - val_loss: 4.2489\n",
            "Epoch 35/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7830 - loss: 4.2460 - val_accuracy: 0.7820 - val_loss: 4.2123\n",
            "Epoch 36/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7896 - loss: 4.2071 - val_accuracy: 0.7868 - val_loss: 4.1773\n",
            "Epoch 37/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7940 - loss: 4.1682 - val_accuracy: 0.7904 - val_loss: 4.1440\n",
            "Epoch 38/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 4.1435 - val_accuracy: 0.7936 - val_loss: 4.1123\n",
            "Epoch 39/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8019 - loss: 4.1062 - val_accuracy: 0.7978 - val_loss: 4.0820\n",
            "Epoch 40/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8013 - loss: 4.0823 - val_accuracy: 0.8011 - val_loss: 4.0530\n",
            "Epoch 41/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8098 - loss: 4.0448 - val_accuracy: 0.8053 - val_loss: 4.0252\n",
            "Epoch 42/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8099 - loss: 4.0204 - val_accuracy: 0.8083 - val_loss: 3.9986\n",
            "Epoch 43/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8115 - loss: 3.9938 - val_accuracy: 0.8107 - val_loss: 3.9731\n",
            "Epoch 44/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8169 - loss: 3.9674 - val_accuracy: 0.8146 - val_loss: 3.9485\n",
            "Epoch 45/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8161 - loss: 3.9458 - val_accuracy: 0.8166 - val_loss: 3.9249\n",
            "Epoch 46/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8210 - loss: 3.9204 - val_accuracy: 0.8186 - val_loss: 3.9021\n",
            "Epoch 47/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8201 - loss: 3.9033 - val_accuracy: 0.8208 - val_loss: 3.8802\n",
            "Epoch 48/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8270 - loss: 3.8735 - val_accuracy: 0.8226 - val_loss: 3.8589\n",
            "Epoch 49/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8289 - loss: 3.8516 - val_accuracy: 0.8257 - val_loss: 3.8384\n",
            "Epoch 50/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8311 - loss: 3.8298 - val_accuracy: 0.8278 - val_loss: 3.8184\n",
            "Training time for MLP task 2 l1_l2 regularization: 197.2790036201477 seconds\n",
            "\n",
            "\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8283 - loss: 3.8217\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mlp_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_9 (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │          \u001b[38;5;34m89,610\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Different optimizers (SDG , ADAM, Ftrl)"
      ],
      "metadata": {
        "id": "Z1oZQfkdqke_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#try : SDG , ADAM, Ftrl\n",
        "optimizers = [{'name':'SGD','obj':tf.keras.optimizers.SGD(learning_rate=0.0001)},\n",
        "              {'name':'Adam','obj':tf.keras.optimizers.Adam(learning_rate=0.0001)},\n",
        "              {'name':'Ftrl','obj':tf.keras.optimizers.Ftrl(learning_rate=0.0001)}]\n",
        "for idx, optimizer in enumerate(optimizers):\n",
        "  mlp_idx = MLP(num_classes=10,\n",
        "            input_shape=(28*28,),\n",
        "            n_layers=2,\n",
        "            n_units=100,\n",
        "            activation='relu',\n",
        "            optim= optimizer['obj'],\n",
        "            loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "            initializer=tf.keras.initializers.RandomNormal(),\n",
        "            reg = tf.keras.regularizers.l2(0.001))\n",
        "\n",
        "  mlp_idx.compile_model()\n",
        "\n",
        "  start = time.time()\n",
        "  mlp_idx.train_model(x_train, y_train, x_val, y_val, epochs=50, batch_size=32)\n",
        "  end = time.time()\n",
        "\n",
        "  print(f\"Training time for MLP task 2 {optimizer['name']} is the optimizer: {end - start} seconds\")\n",
        "  print(\"\\n\")\n",
        "\n",
        "  test_loss, test_acc = mlp_idx.evaluate_model(x_test, y_test)\n",
        "\n",
        "  df_task2.loc[len(df_task2)] =['RandomNormal', 'l2', optimizer['name'],test_loss, test_acc,end - start]\n",
        "\n",
        "  mlp_idx.summary()"
      ],
      "metadata": {
        "id": "O4mTbjNrqjqc",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a67a0da6-1901-48d9-ed0f-e5a17d0d1c53"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.1043 - loss: 2.5367 - val_accuracy: 0.1174 - val_loss: 2.5288\n",
            "Epoch 2/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1216 - loss: 2.5233 - val_accuracy: 0.1373 - val_loss: 2.5143\n",
            "Epoch 3/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1385 - loss: 2.5095 - val_accuracy: 0.1605 - val_loss: 2.5003\n",
            "Epoch 4/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1617 - loss: 2.4936 - val_accuracy: 0.1857 - val_loss: 2.4866\n",
            "Epoch 5/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.1875 - loss: 2.4814 - val_accuracy: 0.2118 - val_loss: 2.4730\n",
            "Epoch 6/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.2124 - loss: 2.4673 - val_accuracy: 0.2390 - val_loss: 2.4596\n",
            "Epoch 7/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.2413 - loss: 2.4546 - val_accuracy: 0.2691 - val_loss: 2.4461\n",
            "Epoch 8/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.2641 - loss: 2.4432 - val_accuracy: 0.2993 - val_loss: 2.4326\n",
            "Epoch 9/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3014 - loss: 2.4286 - val_accuracy: 0.3303 - val_loss: 2.4188\n",
            "Epoch 10/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3346 - loss: 2.4145 - val_accuracy: 0.3591 - val_loss: 2.4049\n",
            "Epoch 11/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3661 - loss: 2.3997 - val_accuracy: 0.3859 - val_loss: 2.3906\n",
            "Epoch 12/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.3895 - loss: 2.3879 - val_accuracy: 0.4101 - val_loss: 2.3761\n",
            "Epoch 13/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4184 - loss: 2.3709 - val_accuracy: 0.4320 - val_loss: 2.3611\n",
            "Epoch 14/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4347 - loss: 2.3581 - val_accuracy: 0.4524 - val_loss: 2.3457\n",
            "Epoch 15/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4578 - loss: 2.3411 - val_accuracy: 0.4680 - val_loss: 2.3299\n",
            "Epoch 16/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4643 - loss: 2.3282 - val_accuracy: 0.4820 - val_loss: 2.3136\n",
            "Epoch 17/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4895 - loss: 2.3089 - val_accuracy: 0.4951 - val_loss: 2.2966\n",
            "Epoch 18/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4961 - loss: 2.2933 - val_accuracy: 0.5064 - val_loss: 2.2792\n",
            "Epoch 19/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5058 - loss: 2.2764 - val_accuracy: 0.5160 - val_loss: 2.2611\n",
            "Epoch 20/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5153 - loss: 2.2578 - val_accuracy: 0.5267 - val_loss: 2.2424\n",
            "Epoch 21/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5246 - loss: 2.2382 - val_accuracy: 0.5359 - val_loss: 2.2231\n",
            "Epoch 22/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5368 - loss: 2.2195 - val_accuracy: 0.5450 - val_loss: 2.2032\n",
            "Epoch 23/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5436 - loss: 2.1991 - val_accuracy: 0.5522 - val_loss: 2.1826\n",
            "Epoch 24/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5484 - loss: 2.1813 - val_accuracy: 0.5585 - val_loss: 2.1615\n",
            "Epoch 25/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5574 - loss: 2.1569 - val_accuracy: 0.5648 - val_loss: 2.1399\n",
            "Epoch 26/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5643 - loss: 2.1350 - val_accuracy: 0.5708 - val_loss: 2.1176\n",
            "Epoch 27/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5743 - loss: 2.1124 - val_accuracy: 0.5765 - val_loss: 2.0949\n",
            "Epoch 28/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5769 - loss: 2.0890 - val_accuracy: 0.5820 - val_loss: 2.0716\n",
            "Epoch 29/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5812 - loss: 2.0657 - val_accuracy: 0.5876 - val_loss: 2.0480\n",
            "Epoch 30/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5896 - loss: 2.0435 - val_accuracy: 0.5931 - val_loss: 2.0239\n",
            "Epoch 31/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6002 - loss: 2.0183 - val_accuracy: 0.5989 - val_loss: 1.9995\n",
            "Epoch 32/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.6017 - loss: 1.9971 - val_accuracy: 0.6060 - val_loss: 1.9748\n",
            "Epoch 33/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6007 - loss: 1.9752 - val_accuracy: 0.6106 - val_loss: 1.9499\n",
            "Epoch 34/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6138 - loss: 1.9426 - val_accuracy: 0.6166 - val_loss: 1.9248\n",
            "Epoch 35/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.6192 - loss: 1.9222 - val_accuracy: 0.6230 - val_loss: 1.8994\n",
            "Epoch 36/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6248 - loss: 1.8967 - val_accuracy: 0.6291 - val_loss: 1.8740\n",
            "Epoch 37/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6317 - loss: 1.8687 - val_accuracy: 0.6353 - val_loss: 1.8485\n",
            "Epoch 38/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6372 - loss: 1.8456 - val_accuracy: 0.6414 - val_loss: 1.8230\n",
            "Epoch 39/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6451 - loss: 1.8178 - val_accuracy: 0.6489 - val_loss: 1.7975\n",
            "Epoch 40/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6528 - loss: 1.7945 - val_accuracy: 0.6548 - val_loss: 1.7721\n",
            "Epoch 41/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6580 - loss: 1.7666 - val_accuracy: 0.6624 - val_loss: 1.7467\n",
            "Epoch 42/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6621 - loss: 1.7434 - val_accuracy: 0.6676 - val_loss: 1.7215\n",
            "Epoch 43/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6771 - loss: 1.7095 - val_accuracy: 0.6731 - val_loss: 1.6965\n",
            "Epoch 44/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6759 - loss: 1.6927 - val_accuracy: 0.6795 - val_loss: 1.6717\n",
            "Epoch 45/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6775 - loss: 1.6718 - val_accuracy: 0.6852 - val_loss: 1.6472\n",
            "Epoch 46/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6879 - loss: 1.6399 - val_accuracy: 0.6918 - val_loss: 1.6230\n",
            "Epoch 47/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.6942 - loss: 1.6180 - val_accuracy: 0.6969 - val_loss: 1.5991\n",
            "Epoch 48/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6972 - loss: 1.5962 - val_accuracy: 0.7015 - val_loss: 1.5756\n",
            "Epoch 49/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7060 - loss: 1.5707 - val_accuracy: 0.7070 - val_loss: 1.5525\n",
            "Epoch 50/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7045 - loss: 1.5517 - val_accuracy: 0.7126 - val_loss: 1.5299\n",
            "Training time for MLP task 2 SGD is the optimizer: 216.73797369003296 seconds\n",
            "\n",
            "\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7025 - loss: 1.5397\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mlp_10\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_10\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_10 (\u001b[38;5;33mSequential\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │          \u001b[38;5;34m89,610\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5691 - loss: 1.7468 - val_accuracy: 0.8809 - val_loss: 0.6066\n",
            "Epoch 2/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8920 - loss: 0.5570 - val_accuracy: 0.9048 - val_loss: 0.4760\n",
            "Epoch 3/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9120 - loss: 0.4560 - val_accuracy: 0.9160 - val_loss: 0.4267\n",
            "Epoch 4/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9246 - loss: 0.4090 - val_accuracy: 0.9212 - val_loss: 0.4010\n",
            "Epoch 5/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9288 - loss: 0.3812 - val_accuracy: 0.9305 - val_loss: 0.3705\n",
            "Epoch 6/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9367 - loss: 0.3512 - val_accuracy: 0.9360 - val_loss: 0.3491\n",
            "Epoch 7/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9420 - loss: 0.3260 - val_accuracy: 0.9401 - val_loss: 0.3312\n",
            "Epoch 8/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9463 - loss: 0.3100 - val_accuracy: 0.9429 - val_loss: 0.3170\n",
            "Epoch 9/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9496 - loss: 0.2943 - val_accuracy: 0.9441 - val_loss: 0.3063\n",
            "Epoch 10/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9527 - loss: 0.2811 - val_accuracy: 0.9469 - val_loss: 0.2932\n",
            "Epoch 11/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9555 - loss: 0.2694 - val_accuracy: 0.9486 - val_loss: 0.2856\n",
            "Epoch 12/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9579 - loss: 0.2587 - val_accuracy: 0.9514 - val_loss: 0.2765\n",
            "Epoch 13/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9596 - loss: 0.2525 - val_accuracy: 0.9528 - val_loss: 0.2699\n",
            "Epoch 14/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9630 - loss: 0.2352 - val_accuracy: 0.9535 - val_loss: 0.2625\n",
            "Epoch 15/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9636 - loss: 0.2315 - val_accuracy: 0.9540 - val_loss: 0.2561\n",
            "Epoch 16/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9658 - loss: 0.2259 - val_accuracy: 0.9567 - val_loss: 0.2494\n",
            "Epoch 17/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9669 - loss: 0.2201 - val_accuracy: 0.9570 - val_loss: 0.2447\n",
            "Epoch 18/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9690 - loss: 0.2122 - val_accuracy: 0.9583 - val_loss: 0.2406\n",
            "Epoch 19/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9692 - loss: 0.2063 - val_accuracy: 0.9579 - val_loss: 0.2360\n",
            "Epoch 20/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9700 - loss: 0.2046 - val_accuracy: 0.9594 - val_loss: 0.2327\n",
            "Epoch 21/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9718 - loss: 0.2005 - val_accuracy: 0.9605 - val_loss: 0.2271\n",
            "Epoch 22/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9734 - loss: 0.1943 - val_accuracy: 0.9608 - val_loss: 0.2234\n",
            "Epoch 23/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9740 - loss: 0.1889 - val_accuracy: 0.9614 - val_loss: 0.2202\n",
            "Epoch 24/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9759 - loss: 0.1813 - val_accuracy: 0.9623 - val_loss: 0.2180\n",
            "Epoch 25/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9757 - loss: 0.1805 - val_accuracy: 0.9631 - val_loss: 0.2146\n",
            "Epoch 26/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9763 - loss: 0.1776 - val_accuracy: 0.9636 - val_loss: 0.2122\n",
            "Epoch 27/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9765 - loss: 0.1762 - val_accuracy: 0.9636 - val_loss: 0.2102\n",
            "Epoch 28/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9775 - loss: 0.1716 - val_accuracy: 0.9642 - val_loss: 0.2080\n",
            "Epoch 29/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9799 - loss: 0.1653 - val_accuracy: 0.9651 - val_loss: 0.2034\n",
            "Epoch 30/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9805 - loss: 0.1622 - val_accuracy: 0.9639 - val_loss: 0.2036\n",
            "Epoch 31/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9816 - loss: 0.1614 - val_accuracy: 0.9653 - val_loss: 0.1997\n",
            "Epoch 32/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9809 - loss: 0.1594 - val_accuracy: 0.9652 - val_loss: 0.1982\n",
            "Epoch 33/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9809 - loss: 0.1570 - val_accuracy: 0.9669 - val_loss: 0.1961\n",
            "Epoch 34/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9820 - loss: 0.1532 - val_accuracy: 0.9662 - val_loss: 0.1944\n",
            "Epoch 35/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9810 - loss: 0.1542 - val_accuracy: 0.9679 - val_loss: 0.1932\n",
            "Epoch 36/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9833 - loss: 0.1494 - val_accuracy: 0.9673 - val_loss: 0.1911\n",
            "Epoch 37/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9829 - loss: 0.1483 - val_accuracy: 0.9667 - val_loss: 0.1903\n",
            "Epoch 38/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9842 - loss: 0.1452 - val_accuracy: 0.9683 - val_loss: 0.1876\n",
            "Epoch 39/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9852 - loss: 0.1433 - val_accuracy: 0.9673 - val_loss: 0.1882\n",
            "Epoch 40/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9851 - loss: 0.1416 - val_accuracy: 0.9681 - val_loss: 0.1848\n",
            "Epoch 41/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9855 - loss: 0.1382 - val_accuracy: 0.9679 - val_loss: 0.1838\n",
            "Epoch 42/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9870 - loss: 0.1361 - val_accuracy: 0.9684 - val_loss: 0.1830\n",
            "Epoch 43/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.1373 - val_accuracy: 0.9681 - val_loss: 0.1818\n",
            "Epoch 44/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9868 - loss: 0.1340 - val_accuracy: 0.9695 - val_loss: 0.1789\n",
            "Epoch 45/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9871 - loss: 0.1322 - val_accuracy: 0.9695 - val_loss: 0.1770\n",
            "Epoch 46/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9868 - loss: 0.1313 - val_accuracy: 0.9697 - val_loss: 0.1764\n",
            "Epoch 47/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9869 - loss: 0.1320 - val_accuracy: 0.9706 - val_loss: 0.1750\n",
            "Epoch 48/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9896 - loss: 0.1263 - val_accuracy: 0.9692 - val_loss: 0.1772\n",
            "Epoch 49/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9875 - loss: 0.1265 - val_accuracy: 0.9697 - val_loss: 0.1736\n",
            "Epoch 50/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9886 - loss: 0.1258 - val_accuracy: 0.9706 - val_loss: 0.1751\n",
            "Training time for MLP task 2 Adam is the optimizer: 226.36067295074463 seconds\n",
            "\n",
            "\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9694 - loss: 0.1778\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mlp_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_11 (\u001b[38;5;33mSequential\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │          \u001b[38;5;34m89,610\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.1119 - loss: 2.3050 - val_accuracy: 0.1106 - val_loss: 2.3026\n",
            "Epoch 2/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.1126 - loss: 2.3026 - val_accuracy: 0.1106 - val_loss: 2.3025\n",
            "Epoch 3/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1136 - loss: 2.3025 - val_accuracy: 0.1106 - val_loss: 2.3025\n",
            "Epoch 4/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1101 - loss: 2.3025 - val_accuracy: 0.1106 - val_loss: 2.3025\n",
            "Epoch 5/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.1130 - loss: 2.3025 - val_accuracy: 0.1106 - val_loss: 2.3025\n",
            "Epoch 6/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.1151 - loss: 2.3025 - val_accuracy: 0.1106 - val_loss: 2.3025\n",
            "Epoch 7/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1147 - loss: 2.3025 - val_accuracy: 0.1106 - val_loss: 2.3025\n",
            "Epoch 8/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.1132 - loss: 2.3025 - val_accuracy: 0.1106 - val_loss: 2.3025\n",
            "Epoch 9/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1139 - loss: 2.3025 - val_accuracy: 0.1106 - val_loss: 2.3025\n",
            "Epoch 10/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1119 - loss: 2.3025 - val_accuracy: 0.1106 - val_loss: 2.3025\n",
            "Epoch 11/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1125 - loss: 2.3025 - val_accuracy: 0.1106 - val_loss: 2.3025\n",
            "Epoch 12/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.1152 - loss: 2.3025 - val_accuracy: 0.1106 - val_loss: 2.3025\n",
            "Epoch 13/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1133 - loss: 2.3025 - val_accuracy: 0.1106 - val_loss: 2.3025\n",
            "Epoch 14/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.1156 - loss: 2.3025 - val_accuracy: 0.1106 - val_loss: 2.3025\n",
            "Epoch 15/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.1130 - loss: 2.3025 - val_accuracy: 0.1106 - val_loss: 2.3025\n",
            "Epoch 16/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.1134 - loss: 2.3025 - val_accuracy: 0.1106 - val_loss: 2.3025\n",
            "Epoch 17/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1146 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3025\n",
            "Epoch 18/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.1107 - loss: 2.3025 - val_accuracy: 0.1106 - val_loss: 2.3025\n",
            "Epoch 19/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1115 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3025\n",
            "Epoch 20/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.1137 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 21/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.1143 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 22/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1158 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 23/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.1138 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 24/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1116 - loss: 2.3025 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 25/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.1121 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 26/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.1138 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 27/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1117 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 28/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.1134 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 29/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1126 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 30/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.1127 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 31/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.1113 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 32/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.1131 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 33/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1132 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 34/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.1128 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 35/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.1127 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 36/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.1111 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 37/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.1138 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 38/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.1123 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 39/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1158 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 40/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.1098 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 41/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.1124 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 42/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.1146 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 43/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.1119 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 44/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.1132 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 45/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1142 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 46/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.1136 - loss: 2.3023 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 47/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1115 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 48/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.1135 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 49/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.1153 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Epoch 50/50\n",
            "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.1098 - loss: 2.3024 - val_accuracy: 0.1106 - val_loss: 2.3024\n",
            "Training time for MLP task 2 Ftrl is the optimizer: 249.8167028427124 seconds\n",
            "\n",
            "\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1121 - loss: 2.3024\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mlp_12\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_12\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_12 (\u001b[38;5;33mSequential\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │          \u001b[38;5;34m89,610\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,610\u001b[0m (350.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,610</span> (350.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare the accuracy, loss, time for all the different designs"
      ],
      "metadata": {
        "id": "nmHj2Nrv-Rmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_task2)"
      ],
      "metadata": {
        "id": "NV3rvMFG6RTm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28bcb320-a44c-4083-d1d1-9fed7838f6b8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    weight init regularization optimizer       Loss  Accuracy        Time\n",
            "0  RandomNormal             l2       SGD   0.916861  0.832571  207.002571\n",
            "1         zeros             l2       SGD   2.301564  0.112571  210.118195\n",
            "2          ones             l2       SGD  68.859261  0.133190  197.121671\n",
            "3  GlorotNormal             l2       SGD   0.826403  0.858667  209.670606\n",
            "4  RandomNormal             l1       SGD   3.832839  0.813619  200.443092\n",
            "5  RandomNormal             l2       SGD   0.918872  0.827619  219.046928\n",
            "6  RandomNormal          l1_l2       SGD   3.824388  0.827762  197.279004\n",
            "7  RandomNormal             l2       SGD   1.538223  0.706000  216.737974\n",
            "8  RandomNormal             l2      Adam   0.174193  0.970571  226.360673\n",
            "9  RandomNormal             l2      Ftrl   2.302361  0.112571  249.816703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results:\n",
        "The best for this dataset is ...\n",
        "\n",
        "Best weight initalization by max accuracy and min loss is **GlorotNormal**.\n",
        "\n",
        "Regularization accuracy is about the same for all (l1, l2, l3) with **l2** with the lowest loss and the fastest time is **l1_l2**.\n",
        "\n",
        "Best optimizer is **Adam** with the highest accuracy at 97% and lowest loss.  \n"
      ],
      "metadata": {
        "id": "P1KzPDXB_r4Y"
      }
    }
  ]
}