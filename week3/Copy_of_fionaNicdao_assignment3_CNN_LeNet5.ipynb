{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: implement your own LeNet-5 for MNIST dataset.\n",
        "\n",
        "\n",
        "*   Change all architecture choices\n",
        "  * number of filters\n",
        "  * size of filters\n",
        "  * activation (use RELU)\n",
        "  * keep the pooling (size and stride) and the padding\n",
        "  * use dropout (dropout rate = 0.5)\n",
        "  * use L2 regularization for dense layers (except last one)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DlR3x9TMvIyU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fiona Nicdao Assigment 3: CNN LeNet-5"
      ],
      "metadata": {
        "id": "HhmxPCNvugEv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6bo55WYKuRmI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## processing the MNIST Dataset\n",
        "* normalize the data\n",
        "* 70% training and 30% testing sets"
      ],
      "metadata": {
        "id": "W0HTMBdBHesk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load mnist dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# normalize the data\n",
        "x_train = np.expand_dims((x_train/255.0),axis=3) # add channel for color\n",
        "x_test = np.expand_dims((x_test/255.0),axis=3)\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Change the data to be split into 70% training set and 30% testing set\n",
        "x = np.concatenate((x_train, x_test))\n",
        "y = np.concatenate((y_train, y_test))\n",
        "train_size = 0.7\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=train_size,\n",
        "                                                    random_state=42)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOIMNBLgWxZj",
        "outputId": "b994da94-7659-4576-b9d7-077287dea336"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(49000, 28, 28, 1)\n",
            "(49000, 10)\n",
            "(21000, 28, 28, 1)\n",
            "(21000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## CNN -LeNet-5\n",
        " * Adam optimizer with 2e-4 learning rate\n",
        " * batch size = 32\n",
        " * number of training epochs = 50\n",
        " * optain the trainging and testing accuracy"
      ],
      "metadata": {
        "id": "2RjL8kqKXiFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(tf.keras.Model):\n",
        "  def __init__(self,conv_layers, pooling_layers, fc_layers,\n",
        "               input_shape, output_shape, activation, loss,\n",
        "               output_activation, w_init,reg_lambda, dropout):\n",
        "    super(LeNet, self).__init__()\n",
        "    self.conv_layers = conv_layers\n",
        "    self.pooling_layers = pooling_layers\n",
        "    self.fc_layers = fc_layers\n",
        "    self.input_shape = input_shape\n",
        "    self.output_shape = output_shape\n",
        "    self.activation = activation\n",
        "    self.optimizer = tf.keras.optimizers.Adam # set and don't change\n",
        "    self.loss = loss\n",
        "    self.output_activation = output_activation\n",
        "    self.w_init = w_init\n",
        "    self.reg_lambda = reg_lambda\n",
        "    self.dropout = dropout\n",
        "    self.learning_rate = 2e-4 # set and don't change\n",
        "    self.batch_size = 32 # set and don't change\n",
        "    self.epochs = 50 # set and don't change\n",
        "    self.regularizer = tf.keras.regularizers.l2(self.reg_lambda)\n",
        "\n",
        "    self.model = self.create_model()\n",
        "\n",
        "  def create_model(self):\n",
        "      model = tf.keras.Sequential()\n",
        "      model.add(tf.keras.layers.Input(shape=self.input_shape))\n",
        "\n",
        "      for conv, pool in zip(self.conv_layers, self.pooling_layers):\n",
        "        model.add(tf.keras.layers.Conv2D(filters=conv[0], kernel_size=conv[1],\n",
        "                                         padding='same',\n",
        "                                         activation=self.activation,\n",
        "                                         kernel_regularizer=self.regularizer,\n",
        "                                         kernel_initializer=self.w_init,))\n",
        "        model.add(tf.keras.layers.AveragePooling2D(pool_size=pool[0], strides=pool[1]))\n",
        "\n",
        "      model.add(tf.keras.layers.Flatten()) # create model makes\n",
        "\n",
        "      for fc in self.fc_layers:\n",
        "        model.add(tf.keras.layers.Dense( fc, activation= self.activation,\n",
        "                                         kernel_regularizer=self.regularizer,\n",
        "                                         kernel_initializer=self.w_init))\n",
        "      # output layer\n",
        "      model.add(tf.keras.layers.Dense(self.output_shape,\n",
        "                                      activation=self.output_activation,\n",
        "                                      kernel_regularizer=self.regularizer,\n",
        "                                      kernel_initializer=self.w_init))\n",
        "\n",
        "      model.compile(optimizer=self.optimizer(learning_rate=self.learning_rate),\n",
        "                    loss=self.loss,\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "      return model\n",
        "\n",
        "  def train(self, x_train, y_train, x_test, y_test):\n",
        "    t0 = time.time()\n",
        "    history = self.model.fit(x_train, y_train,\n",
        "                             epochs=self.epochs,\n",
        "                             batch_size=self.batch_size,\n",
        "                             validation_data=(x_test, y_test))\n",
        "    print(\"training time \", time.time()-t0)\n",
        "    end_time = time.time()-t0\n",
        "    return history, end_time\n",
        "\n",
        "  def evaluate(self, x_test, y_test):\n",
        "    test_loss, test_acc = self.model.evaluate(x_test, y_test)\n",
        "    return test_loss, test_acc\n",
        "    # return self.model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "WvR8uSWWYG2Z"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the Model with different Architecture choices\n",
        "* change number of filters\n",
        "* change size of filters\n",
        "\n",
        "Keep the same\n",
        "* keep the pooling(size and stride) and the padding\n",
        "* use dropout rate = 0.5\n",
        "* use L2 regularizatio for dense layers (except last one)"
      ],
      "metadata": {
        "id": "o9ngzdO3HwgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make a dataframe to compare the accuracy and loss for all the different architecture choices\n",
        "df = pd.DataFrame(columns=['cov_layers','pooling_layers', 'fc_layers', 'Loss', 'Accuracy','Time'])\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRwTqm4SHYb0",
        "outputId": "77e1a86e-cc5e-40e5-dfb6-8c28b09f2925"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [cov_layers, pooling_layers, fc_layers, Loss, Accuracy, Time]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test: Model 1"
      ],
      "metadata": {
        "id": "k1ciy0lDNqNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filter_size, num_filters, input_shape, out_Shape, stride, padding\n",
        "# pooling and window_size, stride, activation, optim, loss, learning rate , batch size\n",
        "# epochs, regularizer, reg_lambda - strength of regularization, dropout, weight initializer\n",
        "\n",
        "conv_layers = [[6,5], [16,5]] # number of filters , 5x5  filers\n",
        "pooling_layers = [[2, 2],[2,2]] # 2x2 and stride by 2 / we have two pooling layers with 2x2 window  and 2 stride\n",
        "fc_layers = [120, 84] # dense layer\n",
        "input_shape = (28,28,1)\n",
        "output_shape = 10\n",
        "activation = 'relu'\n",
        "loss = 'categorical_crossentropy'\n",
        "output_activation = 'softmax'\n",
        "w_init = 'random_normal' # tf.keras.initializers.HeNormal()\n",
        "reg_lambda = 5e-4\n",
        "dropout = 0.5\n",
        "\n",
        "model_1 = LeNet(conv_layers, pooling_layers, fc_layers,\n",
        "               input_shape, output_shape, activation, loss,\n",
        "               output_activation, w_init,reg_lambda, dropout=dropout)\n",
        "\n",
        "history, end_time = model_1.train(x_train, y_train, x_test, y_test)\n",
        "test_loss, test_acc = model_1.evaluate(x_test, y_test)\n",
        "df.loc[len(df)] = [conv_layers, pooling_layers, fc_layers, test_loss, test_acc, end_time]\n",
        "print(df)\n",
        "model_1.model.summary()"
      ],
      "metadata": {
        "id": "9xxH6EaVeHL9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "e0e35893-2b23-421b-bfc9-71ffec4342b5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.6886 - loss: 1.1455 - val_accuracy: 0.9056 - val_loss: 0.3890\n",
            "Epoch 2/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9153 - loss: 0.3486 - val_accuracy: 0.9312 - val_loss: 0.2950\n",
            "Epoch 3/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9422 - loss: 0.2586 - val_accuracy: 0.9530 - val_loss: 0.2278\n",
            "Epoch 4/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9566 - loss: 0.2127 - val_accuracy: 0.9637 - val_loss: 0.1947\n",
            "Epoch 5/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9653 - loss: 0.1841 - val_accuracy: 0.9662 - val_loss: 0.1793\n",
            "Epoch 6/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9720 - loss: 0.1603 - val_accuracy: 0.9695 - val_loss: 0.1667\n",
            "Epoch 7/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9743 - loss: 0.1520 - val_accuracy: 0.9729 - val_loss: 0.1542\n",
            "Epoch 8/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9775 - loss: 0.1376 - val_accuracy: 0.9762 - val_loss: 0.1427\n",
            "Epoch 9/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9801 - loss: 0.1275 - val_accuracy: 0.9770 - val_loss: 0.1386\n",
            "Epoch 10/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9810 - loss: 0.1232 - val_accuracy: 0.9782 - val_loss: 0.1306\n",
            "Epoch 11/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9818 - loss: 0.1158 - val_accuracy: 0.9725 - val_loss: 0.1501\n",
            "Epoch 12/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9832 - loss: 0.1158 - val_accuracy: 0.9800 - val_loss: 0.1228\n",
            "Epoch 13/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9851 - loss: 0.1080 - val_accuracy: 0.9815 - val_loss: 0.1183\n",
            "Epoch 14/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9852 - loss: 0.1039 - val_accuracy: 0.9765 - val_loss: 0.1328\n",
            "Epoch 15/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.1000 - val_accuracy: 0.9817 - val_loss: 0.1160\n",
            "Epoch 16/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.0972 - val_accuracy: 0.9776 - val_loss: 0.1312\n",
            "Epoch 17/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.0982 - val_accuracy: 0.9836 - val_loss: 0.1087\n",
            "Epoch 18/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9877 - loss: 0.0947 - val_accuracy: 0.9808 - val_loss: 0.1184\n",
            "Epoch 19/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9888 - loss: 0.0907 - val_accuracy: 0.9806 - val_loss: 0.1165\n",
            "Epoch 20/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9892 - loss: 0.0896 - val_accuracy: 0.9838 - val_loss: 0.1085\n",
            "Epoch 21/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9892 - loss: 0.0875 - val_accuracy: 0.9837 - val_loss: 0.1058\n",
            "Epoch 22/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9895 - loss: 0.0865 - val_accuracy: 0.9833 - val_loss: 0.1062\n",
            "Epoch 23/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9910 - loss: 0.0832 - val_accuracy: 0.9823 - val_loss: 0.1094\n",
            "Epoch 24/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9908 - loss: 0.0833 - val_accuracy: 0.9833 - val_loss: 0.1063\n",
            "Epoch 25/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9918 - loss: 0.0815 - val_accuracy: 0.9838 - val_loss: 0.1067\n",
            "Epoch 26/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9911 - loss: 0.0813 - val_accuracy: 0.9852 - val_loss: 0.1014\n",
            "Epoch 27/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9919 - loss: 0.0792 - val_accuracy: 0.9842 - val_loss: 0.1029\n",
            "Epoch 28/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0785 - val_accuracy: 0.9851 - val_loss: 0.1015\n",
            "Epoch 29/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.0798 - val_accuracy: 0.9839 - val_loss: 0.1017\n",
            "Epoch 30/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0776 - val_accuracy: 0.9844 - val_loss: 0.1019\n",
            "Epoch 31/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9923 - loss: 0.0762 - val_accuracy: 0.9840 - val_loss: 0.1029\n",
            "Epoch 32/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.0760 - val_accuracy: 0.9851 - val_loss: 0.0995\n",
            "Epoch 33/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0738 - val_accuracy: 0.9850 - val_loss: 0.1012\n",
            "Epoch 34/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0744 - val_accuracy: 0.9830 - val_loss: 0.1069\n",
            "Epoch 35/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9927 - loss: 0.0762 - val_accuracy: 0.9862 - val_loss: 0.0971\n",
            "Epoch 36/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9934 - loss: 0.0734 - val_accuracy: 0.9834 - val_loss: 0.1021\n",
            "Epoch 37/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9939 - loss: 0.0723 - val_accuracy: 0.9855 - val_loss: 0.0994\n",
            "Epoch 38/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.0747 - val_accuracy: 0.9858 - val_loss: 0.0972\n",
            "Epoch 39/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0713 - val_accuracy: 0.9859 - val_loss: 0.0933\n",
            "Epoch 40/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9945 - loss: 0.0703 - val_accuracy: 0.9863 - val_loss: 0.0966\n",
            "Epoch 41/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0710 - val_accuracy: 0.9861 - val_loss: 0.0961\n",
            "Epoch 42/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9939 - loss: 0.0710 - val_accuracy: 0.9874 - val_loss: 0.0917\n",
            "Epoch 43/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0706 - val_accuracy: 0.9868 - val_loss: 0.0921\n",
            "Epoch 44/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9940 - loss: 0.0706 - val_accuracy: 0.9860 - val_loss: 0.0972\n",
            "Epoch 45/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0703 - val_accuracy: 0.9867 - val_loss: 0.0955\n",
            "Epoch 46/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9938 - loss: 0.0706 - val_accuracy: 0.9879 - val_loss: 0.0895\n",
            "Epoch 47/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9947 - loss: 0.0688 - val_accuracy: 0.9879 - val_loss: 0.0913\n",
            "Epoch 48/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9945 - loss: 0.0690 - val_accuracy: 0.9864 - val_loss: 0.0959\n",
            "Epoch 49/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9947 - loss: 0.0685 - val_accuracy: 0.9878 - val_loss: 0.0911\n",
            "Epoch 50/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0681 - val_accuracy: 0.9850 - val_loss: 0.0981\n",
            "training time  418.17834854125977\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.1004\n",
            "          cov_layers    pooling_layers  fc_layers     Loss  Accuracy  \\\n",
            "0  [[6, 5], [16, 5]]  [[2, 2], [2, 2]]  [120, 84]  0.09808  0.984952   \n",
            "\n",
            "         Time  \n",
            "0  418.178465  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m6\u001b[0m)           │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_14                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m6\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │           \u001b[38;5;34m2,416\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_15                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m16\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)                 │          \u001b[38;5;34m94,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)                  │          \u001b[38;5;34m10,164\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m850\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_14                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,416</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_15                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">94,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,164</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">850</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m323,360\u001b[0m (1.23 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">323,360</span> (1.23 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m107,786\u001b[0m (421.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">107,786</span> (421.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m215,574\u001b[0m (842.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">215,574</span> (842.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test: Model 2"
      ],
      "metadata": {
        "id": "5SEo4iMjN6Lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layers = [[1,6], [10,6]] # number of filters , 5x5  filers\n",
        "pooling_layers = [[2, 2],[2,2]] # 2x2 and stride by 2 / we have two pooling layers with 2x2 window  and 2 stride\n",
        "fc_layers = [10, 10,10] # dense layer\n",
        "input_shape = (28,28,1)\n",
        "output_shape = 10\n",
        "activation = 'relu'\n",
        "loss = 'categorical_crossentropy'\n",
        "output_activation = 'softmax'\n",
        "w_init = 'random_normal' # tf.keras.initializers.HeNormal()\n",
        "reg_lambda = 5e-4\n",
        "dropout = 0.5\n",
        "\n",
        "model_2 = LeNet(conv_layers, pooling_layers, fc_layers,\n",
        "               input_shape, output_shape, activation, loss,\n",
        "               output_activation, w_init,reg_lambda, dropout=dropout)\n",
        "\n",
        "history, end_time = model_2.train(x_train, y_train, x_test, y_test)\n",
        "test_loss, test_acc = model_2.evaluate(x_test, y_test)\n",
        "df.loc[len(df)] = [conv_layers, pooling_layers, fc_layers, test_loss, test_acc, end_time]\n",
        "print(df)\n",
        "model_2.model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "imQu6EQhMz-j",
        "outputId": "1d291486-ba1f-45f7-d4d6-584e91dbe435"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.1087 - loss: 2.3043 - val_accuracy: 0.1126 - val_loss: 2.3016\n",
            "Epoch 2/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.1111 - loss: 2.3017 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 3/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.1131 - loss: 2.3010 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 4/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1112 - loss: 2.3015 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 5/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.1115 - loss: 2.3014 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 6/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1129 - loss: 2.3012 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 7/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1129 - loss: 2.3011 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 8/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.1116 - loss: 2.3013 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 9/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1121 - loss: 2.3012 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 10/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.1133 - loss: 2.3012 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 11/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.1136 - loss: 2.3009 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 12/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.3011 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 13/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1102 - loss: 2.3013 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 14/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1120 - loss: 2.3012 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 15/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1119 - loss: 2.3013 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 16/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1128 - loss: 2.3011 - val_accuracy: 0.1126 - val_loss: 2.3011\n",
            "Epoch 17/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1112 - loss: 2.3016 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 18/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1164 - loss: 2.3005 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 19/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1147 - loss: 2.3009 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 20/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1115 - loss: 2.3012 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 21/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.1130 - loss: 2.3012 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 22/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1102 - loss: 2.3018 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 23/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1101 - loss: 2.3016 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 24/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.1130 - loss: 2.3014 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 25/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.1124 - loss: 2.3012 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 26/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1129 - loss: 2.3012 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 27/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1127 - loss: 2.3010 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 28/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1113 - loss: 2.3014 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 29/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.1123 - loss: 2.3013 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 30/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1131 - loss: 2.3013 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 31/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1114 - loss: 2.3016 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 32/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1139 - loss: 2.3010 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 33/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.1126 - loss: 2.3014 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 34/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1134 - loss: 2.3012 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 35/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1113 - loss: 2.3012 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 36/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1128 - loss: 2.3010 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 37/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1130 - loss: 2.3013 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 38/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.1114 - loss: 2.3009 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 39/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.1135 - loss: 2.3012 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 40/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.1110 - loss: 2.3014 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 41/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.1125 - loss: 2.3012 - val_accuracy: 0.1126 - val_loss: 2.3011\n",
            "Epoch 42/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1116 - loss: 2.3014 - val_accuracy: 0.1126 - val_loss: 2.3011\n",
            "Epoch 43/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.1112 - loss: 2.3015 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 44/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1118 - loss: 2.3012 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 45/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1155 - loss: 2.3006 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 46/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.1152 - loss: 2.3009 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 47/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1121 - loss: 2.3016 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 48/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.1099 - loss: 2.3016 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 49/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1125 - loss: 2.3013 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "Epoch 50/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1144 - loss: 2.3011 - val_accuracy: 0.1126 - val_loss: 2.3012\n",
            "training time  441.15723156929016\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1121 - loss: 2.3015\n",
            "          cov_layers    pooling_layers     fc_layers      Loss  Accuracy  \\\n",
            "0  [[6, 5], [16, 5]]  [[2, 2], [2, 2]]     [120, 84]  0.098080  0.984952   \n",
            "1  [[1, 6], [10, 6]]  [[2, 2], [2, 2]]  [10, 10, 10]  2.301179  0.112571   \n",
            "\n",
            "         Time  \n",
            "0  418.178465  \n",
            "1  441.158424  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │              \u001b[38;5;34m37\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_16                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m10\u001b[0m)          │             \u001b[38;5;34m370\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_17                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m10\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_8 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m490\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m4,910\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m110\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m110\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m110\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_16                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">370</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_17                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">490</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,910</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,943\u001b[0m (66.19 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,943</span> (66.19 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,647\u001b[0m (22.06 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,647</span> (22.06 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m11,296\u001b[0m (44.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,296</span> (44.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test: Model 3"
      ],
      "metadata": {
        "id": "T_ReUfM_N-kr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layers = [[50,5], [100,5]] # number of filters , 5x5  filers\n",
        "pooling_layers = [[2, 2],[2,2]] # 2x2 and stride by 2 / we have two pooling layers with 2x2 window  and 2 stride\n",
        "fc_layers = [200, 100,50] # dense layer\n",
        "input_shape = (28,28,1)\n",
        "output_shape = 10\n",
        "activation = 'relu'\n",
        "loss = 'categorical_crossentropy'\n",
        "output_activation = 'softmax'\n",
        "w_init = 'random_normal' # tf.keras.initializers.HeNormal()\n",
        "reg_lambda = 5e-4\n",
        "dropout = 0.5\n",
        "\n",
        "model_3 = LeNet(conv_layers, pooling_layers, fc_layers,\n",
        "               input_shape, output_shape, activation, loss,\n",
        "               output_activation, w_init,reg_lambda, dropout=dropout)\n",
        "\n",
        "history, end_time = model_3.train(x_train, y_train, x_test, y_test)\n",
        "test_loss, test_acc = model_3.evaluate(x_test, y_test)\n",
        "df.loc[len(df)] = [conv_layers, pooling_layers, fc_layers, test_loss, test_acc, end_time]\n",
        "print(df)\n",
        "model_3.model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PloHzli2U4KM",
        "outputId": "86469e0a-179b-4022-b527-1d10ca9a43ee"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.7683 - loss: 1.5443 - val_accuracy: 0.9617 - val_loss: 0.5265\n",
            "Epoch 2/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9631 - loss: 0.4717 - val_accuracy: 0.9734 - val_loss: 0.3332\n",
            "Epoch 3/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9719 - loss: 0.3114 - val_accuracy: 0.9727 - val_loss: 0.2593\n",
            "Epoch 4/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9765 - loss: 0.2290 - val_accuracy: 0.9743 - val_loss: 0.2050\n",
            "Epoch 5/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9802 - loss: 0.1819 - val_accuracy: 0.9799 - val_loss: 0.1648\n",
            "Epoch 6/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9814 - loss: 0.1563 - val_accuracy: 0.9808 - val_loss: 0.1526\n",
            "Epoch 7/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9819 - loss: 0.1433 - val_accuracy: 0.9830 - val_loss: 0.1365\n",
            "Epoch 8/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9834 - loss: 0.1338 - val_accuracy: 0.9801 - val_loss: 0.1428\n",
            "Epoch 9/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9863 - loss: 0.1205 - val_accuracy: 0.9825 - val_loss: 0.1294\n",
            "Epoch 10/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9876 - loss: 0.1135 - val_accuracy: 0.9840 - val_loss: 0.1237\n",
            "Epoch 11/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9882 - loss: 0.1075 - val_accuracy: 0.9850 - val_loss: 0.1155\n",
            "Epoch 12/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9887 - loss: 0.1062 - val_accuracy: 0.9796 - val_loss: 0.1323\n",
            "Epoch 13/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9895 - loss: 0.1005 - val_accuracy: 0.9846 - val_loss: 0.1162\n",
            "Epoch 14/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9896 - loss: 0.0981 - val_accuracy: 0.9873 - val_loss: 0.1049\n",
            "Epoch 15/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9896 - loss: 0.0977 - val_accuracy: 0.9832 - val_loss: 0.1176\n",
            "Epoch 16/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9902 - loss: 0.0953 - val_accuracy: 0.9844 - val_loss: 0.1124\n",
            "Epoch 17/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9902 - loss: 0.0939 - val_accuracy: 0.9838 - val_loss: 0.1123\n",
            "Epoch 18/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9911 - loss: 0.0910 - val_accuracy: 0.9826 - val_loss: 0.1173\n",
            "Epoch 19/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9912 - loss: 0.0887 - val_accuracy: 0.9852 - val_loss: 0.1048\n",
            "Epoch 20/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9918 - loss: 0.0873 - val_accuracy: 0.9867 - val_loss: 0.1009\n",
            "Epoch 21/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9918 - loss: 0.0865 - val_accuracy: 0.9858 - val_loss: 0.1045\n",
            "Epoch 22/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9932 - loss: 0.0823 - val_accuracy: 0.9866 - val_loss: 0.0989\n",
            "Epoch 23/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9926 - loss: 0.0849 - val_accuracy: 0.9834 - val_loss: 0.1142\n",
            "Epoch 24/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9930 - loss: 0.0817 - val_accuracy: 0.9876 - val_loss: 0.0966\n",
            "Epoch 25/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9925 - loss: 0.0819 - val_accuracy: 0.9867 - val_loss: 0.1014\n",
            "Epoch 26/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9936 - loss: 0.0808 - val_accuracy: 0.9881 - val_loss: 0.0945\n",
            "Epoch 27/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9938 - loss: 0.0795 - val_accuracy: 0.9881 - val_loss: 0.0943\n",
            "Epoch 28/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9936 - loss: 0.0783 - val_accuracy: 0.9855 - val_loss: 0.1036\n",
            "Epoch 29/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9933 - loss: 0.0786 - val_accuracy: 0.9870 - val_loss: 0.0967\n",
            "Epoch 30/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9928 - loss: 0.0793 - val_accuracy: 0.9877 - val_loss: 0.0970\n",
            "Epoch 31/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.0780 - val_accuracy: 0.9870 - val_loss: 0.0989\n",
            "Epoch 32/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9927 - loss: 0.0793 - val_accuracy: 0.9881 - val_loss: 0.0929\n",
            "Epoch 33/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9936 - loss: 0.0771 - val_accuracy: 0.9880 - val_loss: 0.0930\n",
            "Epoch 34/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9938 - loss: 0.0759 - val_accuracy: 0.9884 - val_loss: 0.0895\n",
            "Epoch 35/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9947 - loss: 0.0749 - val_accuracy: 0.9872 - val_loss: 0.0968\n",
            "Epoch 36/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9945 - loss: 0.0759 - val_accuracy: 0.9874 - val_loss: 0.0953\n",
            "Epoch 37/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9943 - loss: 0.0742 - val_accuracy: 0.9887 - val_loss: 0.0912\n",
            "Epoch 38/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9950 - loss: 0.0734 - val_accuracy: 0.9824 - val_loss: 0.1105\n",
            "Epoch 39/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9942 - loss: 0.0749 - val_accuracy: 0.9870 - val_loss: 0.0957\n",
            "Epoch 40/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9945 - loss: 0.0739 - val_accuracy: 0.9870 - val_loss: 0.0958\n",
            "Epoch 41/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9948 - loss: 0.0742 - val_accuracy: 0.9880 - val_loss: 0.0916\n",
            "Epoch 42/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9956 - loss: 0.0721 - val_accuracy: 0.9876 - val_loss: 0.0939\n",
            "Epoch 43/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9943 - loss: 0.0737 - val_accuracy: 0.9880 - val_loss: 0.0927\n",
            "Epoch 44/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9945 - loss: 0.0723 - val_accuracy: 0.9861 - val_loss: 0.0976\n",
            "Epoch 45/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9946 - loss: 0.0721 - val_accuracy: 0.9883 - val_loss: 0.0935\n",
            "Epoch 46/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9949 - loss: 0.0724 - val_accuracy: 0.9875 - val_loss: 0.0917\n",
            "Epoch 47/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9955 - loss: 0.0711 - val_accuracy: 0.9865 - val_loss: 0.0956\n",
            "Epoch 48/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9951 - loss: 0.0722 - val_accuracy: 0.9874 - val_loss: 0.0930\n",
            "Epoch 49/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9952 - loss: 0.0723 - val_accuracy: 0.9886 - val_loss: 0.0913\n",
            "Epoch 50/50\n",
            "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9956 - loss: 0.0706 - val_accuracy: 0.9871 - val_loss: 0.0943\n",
            "training time  475.29735016822815\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0944\n",
            "            cov_layers    pooling_layers       fc_layers      Loss  Accuracy  \\\n",
            "0    [[6, 5], [16, 5]]  [[2, 2], [2, 2]]       [120, 84]  0.098080  0.984952   \n",
            "1    [[1, 6], [10, 6]]  [[2, 2], [2, 2]]    [10, 10, 10]  2.301179  0.112571   \n",
            "2  [[50, 5], [100, 5]]  [[2, 2], [2, 2]]  [200, 100, 50]  0.094274  0.987143   \n",
            "\n",
            "         Time  \n",
            "0  418.178465  \n",
            "1  441.158424  \n",
            "2  475.297429  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │           \u001b[38;5;34m1,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_22                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m100\u001b[0m)         │         \u001b[38;5;34m125,100\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_23                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m100\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_11 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4900\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │         \u001b[38;5;34m980,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m20,100\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │           \u001b[38;5;34m5,050\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m510\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_22                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">125,100</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_23                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4900</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">980,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,100</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,396,782\u001b[0m (12.96 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,396,782</span> (12.96 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,132,260\u001b[0m (4.32 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,132,260</span> (4.32 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,264,522\u001b[0m (8.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,264,522</span> (8.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary of 3 different models"
      ],
      "metadata": {
        "id": "LbuFzA_TVLH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBfblhxwVQ-9",
        "outputId": "db5809c7-355f-4da7-be5b-87be6c83d428"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            cov_layers    pooling_layers       fc_layers      Loss  Accuracy  \\\n",
            "0    [[6, 5], [16, 5]]  [[2, 2], [2, 2]]       [120, 84]  0.098080  0.984952   \n",
            "1    [[1, 6], [10, 6]]  [[2, 2], [2, 2]]    [10, 10, 10]  2.301179  0.112571   \n",
            "2  [[50, 5], [100, 5]]  [[2, 2], [2, 2]]  [200, 100, 50]  0.094274  0.987143   \n",
            "\n",
            "         Time  \n",
            "0  418.178465  \n",
            "1  441.158424  \n",
            "2  475.297429  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Results:\n",
        "\n",
        "The first model is the one from the class / slides from week 3 module, this is my baseline model to compare my other test.\n",
        "\n",
        "The second model I made the convolutional layers only 1 filter of 6x6 filter and then 10 filters of 6x6 filter. The same pooling layers and lowered the dense layers to [10, 10, 10]. The results is a greater loss value and a significally lower accuracy of only 11.2% so you need more filters for the model to have a better accuracy and loss value.\n",
        "\n",
        "The third model I made the convolutional layers with 50 filters of 5x5 filter and then 100 filters of 5x5. The same pooling layers and increased the dense layers to be [200,100, 50]. The results is an loss value and accuracy similar to the first model. So adding a lot more convolutional layers and dense layers does not make the loss value and accuracy significally better.\n"
      ],
      "metadata": {
        "id": "JMGU2ft0VTuY"
      }
    }
  ]
}